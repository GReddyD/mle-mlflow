{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "task1_header",
   "metadata": {},
   "source": [
    "# –ú–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –ü—Ä–∞–∫—Ç–∏–∫–∞\n",
    "\n",
    "## –ó–∞–¥–∞–Ω–∏–µ 1\n",
    "\n",
    "–û—Ç–±–µ—Ä–∏—Ç–µ –¥–µ—Å—è—Ç—å –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –º–µ—Ç–æ–¥–æ–≤ **SFS** –∏ **SBS**. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–∞–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:\n",
    "\n",
    "- –ø–∞—Ä–∞–º–µ—Ç—Ä –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–∞–≤–µ–Ω **4**;\n",
    "- —Ñ—É–Ω–∫—Ü–∏—è `floating=False`, —Ç–æ –µ—Å—Ç—å –≤—ã–∫–ª—é—á–µ–Ω–∞;\n",
    "- –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ—Ü–µ–Ω—â–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º **—Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞** c —á–∏—Å–ª–æ–º –¥–µ—Ä–µ–≤—å–µ–≤ **300**, –∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–æ–π –±—É–¥–µ—Ç `roc_auc`.\n",
    "\n",
    "–ò–º–µ–Ω–∞ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ `top_sfs` –∏ `top_sbs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv('../.env')\n",
    "\n",
    "print(\"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "data_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: (7043, 22)\n",
      "\n",
      "–ö–æ–ª–æ–Ω–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞:\n",
      "['id', 'customer_id', 'begin_date', 'end_date', 'type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'gender', 'senior_citizen', 'partner', 'dependents', 'multiple_lines', 'target']\n",
      "\n",
      "–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>...</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2744</td>\n",
       "      <td>9637-CDTKZ</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>114.10</td>\n",
       "      <td>8086.40</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2746</td>\n",
       "      <td>3946-JEWRQ</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>95.20</td>\n",
       "      <td>4563.00</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2748</td>\n",
       "      <td>7873-CVMAW</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>88.55</td>\n",
       "      <td>6362.35</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2750</td>\n",
       "      <td>0463-WZZKO</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>20.75</td>\n",
       "      <td>67.10</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2752</td>\n",
       "      <td>3494-JCHRQ</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.05</td>\n",
       "      <td>70.05</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id customer_id begin_date   end_date            type paperless_billing  \\\n",
       "0  2744  9637-CDTKZ 2014-02-01        NaT        Two year               Yes   \n",
       "1  2746  3946-JEWRQ 2016-03-01        NaT        One year               Yes   \n",
       "2  2748  7873-CVMAW 2014-02-01        NaT        Two year                No   \n",
       "3  2750  0463-WZZKO 2019-11-01        NaT  Month-to-month               Yes   \n",
       "4  2752  3494-JCHRQ 2019-12-01 2020-01-01  Month-to-month               Yes   \n",
       "\n",
       "            payment_method  monthly_charges  total_charges internet_service  \\\n",
       "0  Credit card (automatic)           114.10        8086.40      Fiber optic   \n",
       "1  Credit card (automatic)            95.20        4563.00      Fiber optic   \n",
       "2  Credit card (automatic)            88.55        6362.35              DSL   \n",
       "3  Credit card (automatic)            20.75          67.10             None   \n",
       "4         Electronic check            70.05          70.05      Fiber optic   \n",
       "\n",
       "   ... device_protection tech_support streaming_tv streaming_movies gender  \\\n",
       "0  ...               Yes          Yes          Yes              Yes   Male   \n",
       "1  ...                No           No          Yes              Yes   Male   \n",
       "2  ...               Yes          Yes          Yes              Yes   Male   \n",
       "3  ...              None         None         None             None   Male   \n",
       "4  ...                No           No           No               No   Male   \n",
       "\n",
       "  senior_citizen partner  dependents multiple_lines target  \n",
       "0              0     Yes          No            Yes      0  \n",
       "1              0     Yes          No            Yes      0  \n",
       "2              0      No          No            Yes      0  \n",
       "3              0      No          No             No      0  \n",
       "4              0      No          No             No      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(f\"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}\")\n",
    "print(f\"\\n–ö–æ–ª–æ–Ω–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\n–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "data_prep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ['type', 'paperless_billing', 'payment_method', 'internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'gender', 'partner', 'dependents', 'multiple_lines']\n",
      "\n",
      "üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:\n",
      "  X_train: (5634, 17)\n",
      "  X_test: (1409, 17)\n",
      "  y_train: (5634,)\n",
      "  y_test: (1409,)\n",
      "\n",
      "  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 17\n",
      "  –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: ['type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'gender', 'senior_citizen', 'partner', 'dependents', 'multiple_lines']\n",
      "\n",
      "  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ train: [4139 1495]\n",
      "  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ test: [1035  374]\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "# –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "columns_to_drop = ['id', 'customer_id', 'begin_date', 'end_date']\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —á–∏—Å–ª–æ–≤—ã–µ\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_columns = df_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {categorical_columns.tolist()}\")\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "X = df_clean.drop('target', axis=1)\n",
    "y = df_clean['target']\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"\\n  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}\")\n",
    "print(f\"  –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.columns.tolist()}\")\n",
    "print(f\"\\n  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ train: {np.bincount(y_train)}\")\n",
    "print(f\"  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feature_selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–û–¢–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í –° –ü–û–ú–û–©–¨–Æ SFS –ò SBS\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ Sequential Forward Selection (SFS)...\n",
      "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\n",
      "\n",
      "‚úÖ SFS –∑–∞–≤–µ—Ä—à—ë–Ω!\n",
      "–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏–Ω–¥–µ–∫—Å—ã): [0, 1, 2, 3, 4, 5, 6, 7, 9, 10]\n",
      "–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è): ['type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'internet_service', 'online_security', 'online_backup', 'tech_support', 'streaming_tv']\n",
      "\n",
      "2Ô∏è‚É£ Sequential Backward Selection (SBS)...\n",
      "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\n",
      "\n",
      "‚úÖ SBS –∑–∞–≤–µ—Ä—à—ë–Ω!\n",
      "–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏–Ω–¥–µ–∫—Å—ã): [0, 1, 2, 3, 4, 5, 7, 11, 12, 14]\n",
      "–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è): ['type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'internet_service', 'online_backup', 'streaming_movies', 'gender', 'partner']\n",
      "\n",
      "======================================================================\n",
      "–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¢–ë–û–†–ê –ü–†–ò–ó–ù–ê–ö–û–í\n",
      "======================================================================\n",
      "\n",
      "Sequential Forward Selection (k=10)\n",
      "CV Score:\n",
      "0.8165750193508001\n",
      "\n",
      "Sequential Backward Selection (k=10)\n",
      "CV Score:\n",
      "0.8206442653287767\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"–û–¢–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í –° –ü–û–ú–û–©–¨–Æ SFS –ò SBS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ü–µ–Ω—â–∏–∫–∞ - Random Forest —Å 300 –¥–µ—Ä–µ–≤—å—è–º–∏\n",
    "estimator = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Sequential Forward Selection (SFS)\n",
    "print(\"\\n1Ô∏è‚É£ Sequential Forward Selection (SFS)...\")\n",
    "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\")\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator,\n",
    "    k_features=10,  # –æ—Ç–±–∏—Ä–∞–µ–º 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    forward=True,   # forward selection\n",
    "    floating=False, # floating –≤—ã–∫–ª—é—á–µ–Ω\n",
    "    scoring='roc_auc',\n",
    "    cv=4,           # –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è = 4\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è SFS\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º—ë–Ω –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "top_sfs = list(X.columns[list(sfs.k_feature_idx_)])\n",
    "\n",
    "print(f\"\\n‚úÖ SFS –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n",
    "print(f\"–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏–Ω–¥–µ–∫—Å—ã): {list(sfs.k_feature_idx_)}\")\n",
    "print(f\"–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è): {top_sfs}\")\n",
    "\n",
    "# Sequential Backward Selection (SBS)\n",
    "print(\"\\n2Ô∏è‚É£ Sequential Backward Selection (SBS)...\")\n",
    "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\")\n",
    "\n",
    "sbs = SequentialFeatureSelector(\n",
    "    estimator,\n",
    "    k_features=10,  # –æ—Ç–±–∏—Ä–∞–µ–º 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    forward=False,  # backward selection\n",
    "    floating=False, # floating –≤—ã–∫–ª—é—á–µ–Ω\n",
    "    scoring='roc_auc',\n",
    "    cv=4,           # –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è = 4\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è SBS\n",
    "sbs = sbs.fit(X_train, y_train)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º—ë–Ω –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "top_sbs = list(X.columns[list(sbs.k_feature_idx_)])\n",
    "\n",
    "print(f\"\\n‚úÖ SBS –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n",
    "print(f\"–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏–Ω–¥–µ–∫—Å—ã): {list(sbs.k_feature_idx_)}\")\n",
    "print(f\"–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è): {top_sbs}\")\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¢–ë–û–†–ê –ü–†–ò–ó–ù–ê–ö–û–í\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print('\\nSequential Forward Selection (k=10)')\n",
    "print('CV Score:')\n",
    "print(sfs.k_score_)\n",
    "\n",
    "print('\\nSequential Backward Selection (k=10)')\n",
    "print('CV Score:')\n",
    "print(sbs.k_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–°–†–ê–í–ù–ï–ù–ò–ï –û–¢–û–ë–†–ê–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í\n",
      "======================================================================\n",
      "\n",
      "üîÑ –û–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (7):\n",
      "['payment_method', 'monthly_charges', 'online_backup', 'internet_service', 'paperless_billing', 'total_charges', 'type']\n",
      "\n",
      "‚û°Ô∏è  –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–ª—è SFS (3):\n",
      "['tech_support', 'online_security', 'streaming_tv']\n",
      "\n",
      "‚¨ÖÔ∏è  –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–ª—è SBS (3):\n",
      "['streaming_movies', 'partner', 'gender']\n",
      "\n",
      "üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CV Score:\n",
      "  SFS ROC-AUC: 0.8166\n",
      "  SBS ROC-AUC: 0.8206\n",
      "  –†–∞–∑–Ω–∏—Ü–∞: 0.0041\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"–°–†–ê–í–ù–ï–ù–ò–ï –û–¢–û–ë–†–ê–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –û–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "common_features = list(set(top_sfs) & set(top_sbs))\n",
    "print(f\"\\nüîÑ –û–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(common_features)}):\")\n",
    "print(common_features)\n",
    "\n",
    "# –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–ª—è SFS\n",
    "unique_sfs = list(set(top_sfs) - set(top_sbs))\n",
    "print(f\"\\n‚û°Ô∏è  –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–ª—è SFS ({len(unique_sfs)}):\")\n",
    "print(unique_sfs)\n",
    "\n",
    "# –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–ª—è SBS\n",
    "unique_sbs = list(set(top_sbs) - set(top_sfs))\n",
    "print(f\"\\n‚¨ÖÔ∏è  –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–ª—è SBS ({len(unique_sbs)}):\")\n",
    "print(unique_sbs)\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CV Score\n",
    "print(f\"\\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CV Score:\")\n",
    "print(f\"  SFS ROC-AUC: {sfs.k_score_:.4f}\")\n",
    "print(f\"  SBS ROC-AUC: {sbs.k_score_:.4f}\")\n",
    "print(f\"  –†–∞–∑–Ω–∏—Ü–∞: {abs(sfs.k_score_ - sbs.k_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "model_training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ù–ê –û–¢–û–ë–†–ê–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–•\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ –ú–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö SFS...\n",
      "  ROC-AUC: 0.8179\n",
      "  Accuracy: 0.7913\n",
      "\n",
      "2Ô∏è‚É£ –ú–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö SBS...\n",
      "  ROC-AUC: 0.8334\n",
      "  Accuracy: 0.7906\n",
      "\n",
      "3Ô∏è‚É£ –ú–æ–¥–µ–ª—å –Ω–∞ –í–°–ï–• –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...\n",
      "  ROC-AUC: 0.8330\n",
      "  Accuracy: 0.8013\n",
      "\n",
      "======================================================================\n",
      "üìä –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï\n",
      "======================================================================\n",
      "\n",
      "–ú–æ–¥–µ–ª—å            | –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ | ROC-AUC  | Accuracy\n",
      "------------------------------------------------------------\n",
      "SFS               |        10 | 0.8179   | 0.7913\n",
      "SBS               |        10 | 0.8334   | 0.7906\n",
      "–í–°–ï –ø—Ä–∏–∑–Ω–∞–∫–∏      |        17 | 0.8330   | 0.8013\n",
      "\n",
      "‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ù–ê –û–¢–û–ë–†–ê–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö SFS\n",
    "print(\"\\n1Ô∏è‚É£ –ú–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö SFS...\")\n",
    "X_train_sfs = X_train[top_sfs]\n",
    "X_test_sfs = X_test[top_sfs]\n",
    "\n",
    "model_sfs = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model_sfs.fit(X_train_sfs, y_train)\n",
    "y_pred_sfs = model_sfs.predict(X_test_sfs)\n",
    "y_proba_sfs = model_sfs.predict_proba(X_test_sfs)[:, 1]\n",
    "\n",
    "roc_auc_sfs = roc_auc_score(y_test, y_proba_sfs)\n",
    "accuracy_sfs = accuracy_score(y_test, y_pred_sfs)\n",
    "\n",
    "print(f\"  ROC-AUC: {roc_auc_sfs:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy_sfs:.4f}\")\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö SBS\n",
    "print(\"\\n2Ô∏è‚É£ –ú–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö SBS...\")\n",
    "X_train_sbs = X_train[top_sbs]\n",
    "X_test_sbs = X_test[top_sbs]\n",
    "\n",
    "model_sbs = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model_sbs.fit(X_train_sbs, y_train)\n",
    "y_pred_sbs = model_sbs.predict(X_test_sbs)\n",
    "y_proba_sbs = model_sbs.predict_proba(X_test_sbs)[:, 1]\n",
    "\n",
    "roc_auc_sbs = roc_auc_score(y_test, y_proba_sbs)\n",
    "accuracy_sbs = accuracy_score(y_test, y_pred_sbs)\n",
    "\n",
    "print(f\"  ROC-AUC: {roc_auc_sbs:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy_sbs:.4f}\")\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "print(\"\\n3Ô∏è‚É£ –ú–æ–¥–µ–ª—å –Ω–∞ –í–°–ï–• –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...\")\n",
    "model_all = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model_all.fit(X_train, y_train)\n",
    "y_pred_all = model_all.predict(X_test)\n",
    "y_proba_all = model_all.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_all = roc_auc_score(y_test, y_proba_all)\n",
    "accuracy_all = accuracy_score(y_test, y_pred_all)\n",
    "\n",
    "print(f\"  ROC-AUC: {roc_auc_all:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy_all:.4f}\")\n",
    "\n",
    "# –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n–ú–æ–¥–µ–ª—å            | –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ | ROC-AUC  | Accuracy\")\n",
    "print(f\"-\" * 60)\n",
    "print(f\"SFS               | {len(top_sfs):9} | {roc_auc_sfs:.4f}   | {accuracy_sfs:.4f}\")\n",
    "print(f\"SBS               | {len(top_sbs):9} | {roc_auc_sbs:.4f}   | {accuracy_sbs:.4f}\")\n",
    "print(f\"–í–°–ï –ø—Ä–∏–∑–Ω–∞–∫–∏      | {X.shape[1]:9} | {roc_auc_all:.4f}   | {accuracy_all:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "final_output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò\n",
      "======================================================================\n",
      "\n",
      "top_sfs = ['type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'internet_service', 'online_security', 'online_backup', 'tech_support', 'streaming_tv']\n",
      "\n",
      "top_sbs = ['type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'internet_service', 'online_backup', 'streaming_movies', 'gender', 'partner']\n",
      "\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SFS: 10\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SBS: 10\n"
     ]
    }
   ],
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\ntop_sfs = {top_sfs}\")\n",
    "print(f\"\\ntop_sbs = {top_sbs}\")\n",
    "\n",
    "print(f\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SFS: {len(top_sfs)}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SBS: {len(top_sbs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccnjk9kw34",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2\n",
    "\n",
    "–°–æ–∑–¥–∞–π—Ç–µ –¥–≤–∞ —Å–ø–∏—Å–∫–∞ `list` –≤ Python, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—É—Ç—ë–º **–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è** –∏ **–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è**. \n",
    "\n",
    "–§–∞–π–ª –¥–ª—è –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏—Ö—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤ –Ω–∞–∑–æ–≤–∏—Ç–µ `interc_features`, –¥–ª—è –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏—Ö—Å—è ‚Äî `union_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mosrpa1er3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–ó–ê–î–ê–ù–ò–ï 2: –ü–ï–†–ï–°–ï–ß–ï–ù–ò–ï –ò –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í\n",
      "======================================================================\n",
      "\n",
      "üîÑ –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (interc_features):\n",
      "   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: 7\n",
      "   –ü—Ä–∏–∑–Ω–∞–∫–∏: ['internet_service', 'monthly_charges', 'online_backup', 'paperless_billing', 'payment_method', 'total_charges', 'type']\n",
      "\n",
      "üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (union_features):\n",
      "   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: 13\n",
      "   –ü—Ä–∏–∑–Ω–∞–∫–∏: ['gender', 'internet_service', 'monthly_charges', 'online_backup', 'online_security', 'paperless_billing', 'partner', 'payment_method', 'streaming_movies', 'streaming_tv', 'tech_support', 'total_charges', 'type']\n",
      "\n",
      "üìä –ê–Ω–∞–ª–∏–∑:\n",
      "   SFS –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 10\n",
      "   SBS –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 10\n",
      "   –û–±—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 7\n",
      "   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤—Å–µ–≥–æ: 13\n",
      "   –¢–æ–ª—å–∫–æ –≤ SFS: 3\n",
      "   –¢–æ–ª—å–∫–æ –≤ SBS: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"–ó–ê–î–ê–ù–ò–ï 2: –ü–ï–†–ï–°–ï–ß–ï–ù–ò–ï –ò –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–æ–±—â–∏–µ –¥–ª—è SFS –∏ SBS)\n",
    "interc_features = list(set(top_sfs) & set(top_sbs))\n",
    "\n",
    "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑ SFS –∏ SBS)\n",
    "union_features = list(set(top_sfs) | set(top_sbs))\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "interc_features.sort()\n",
    "union_features.sort()\n",
    "\n",
    "print(f\"\\nüîÑ –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (interc_features):\")\n",
    "print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(interc_features)}\")\n",
    "print(f\"   –ü—Ä–∏–∑–Ω–∞–∫–∏: {interc_features}\")\n",
    "\n",
    "print(f\"\\nüîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (union_features):\")\n",
    "print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(union_features)}\")\n",
    "print(f\"   –ü—Ä–∏–∑–Ω–∞–∫–∏: {union_features}\")\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "print(f\"\\nüìä –ê–Ω–∞–ª–∏–∑:\")\n",
    "print(f\"   SFS –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(top_sfs)}\")\n",
    "print(f\"   SBS –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(top_sbs)}\")\n",
    "print(f\"   –û–±—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(interc_features)}\")\n",
    "print(f\"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤—Å–µ–≥–æ: {len(union_features)}\")\n",
    "print(f\"   –¢–æ–ª—å–∫–æ –≤ SFS: {len(set(top_sfs) - set(top_sbs))}\")\n",
    "print(f\"   –¢–æ–ª—å–∫–æ –≤ SBS: {len(set(top_sbs) - set(top_sfs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec5fpel7yjh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ú–ù–û–ñ–ï–°–¢–í\n",
      "======================================================================\n",
      "\n",
      "üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n",
      "\n",
      "‚û°Ô∏è  –¢–æ–ª—å–∫–æ –≤ SFS (3 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):\n",
      "   ['online_security', 'streaming_tv', 'tech_support']\n",
      "\n",
      "‚¨ÖÔ∏è  –¢–æ–ª—å–∫–æ –≤ SBS (3 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):\n",
      "   ['gender', 'partner', 'streaming_movies']\n",
      "\n",
      "üîÑ –û–±—â–∏–µ –¥–ª—è SFS –∏ SBS (7 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):\n",
      "   ['internet_service', 'monthly_charges', 'online_backup', 'paperless_billing', 'payment_method', 'total_charges', 'type']\n",
      "\n",
      "======================================================================\n",
      "‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 2\n",
      "======================================================================\n",
      "\n",
      "interc_features = ['internet_service', 'monthly_charges', 'online_backup', 'paperless_billing', 'payment_method', 'total_charges', 'type']\n",
      "\n",
      "union_features = ['gender', 'internet_service', 'monthly_charges', 'online_backup', 'online_security', 'paperless_billing', 'partner', 'payment_method', 'streaming_movies', 'streaming_tv', 'tech_support', 'total_charges', 'type']\n"
     ]
    }
   ],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è\n",
    "print(\"=\"*70)\n",
    "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ú–ù–û–ñ–ï–°–¢–í\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\")\n",
    "\n",
    "# –¢–æ–ª—å–∫–æ –≤ SFS\n",
    "only_sfs = list(set(top_sfs) - set(top_sbs))\n",
    "only_sfs.sort()\n",
    "print(f\"\\n‚û°Ô∏è  –¢–æ–ª—å–∫–æ –≤ SFS ({len(only_sfs)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):\")\n",
    "print(f\"   {only_sfs}\")\n",
    "\n",
    "# –¢–æ–ª—å–∫–æ –≤ SBS\n",
    "only_sbs = list(set(top_sbs) - set(top_sfs))\n",
    "only_sbs.sort()\n",
    "print(f\"\\n‚¨ÖÔ∏è  –¢–æ–ª—å–∫–æ –≤ SBS ({len(only_sbs)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):\")\n",
    "print(f\"   {only_sbs}\")\n",
    "\n",
    "# –û–±—â–∏–µ\n",
    "print(f\"\\nüîÑ –û–±—â–∏–µ –¥–ª—è SFS –∏ SBS ({len(interc_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):\")\n",
    "print(f\"   {interc_features}\")\n",
    "\n",
    "# –§–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 2\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\ninterc_features = {interc_features}\")\n",
    "print(f\"\\nunion_features = {union_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1jbp6nux4vq",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 3\n",
    "\n",
    "–õ–æ–≥–∏—Ä—É–π—Ç–µ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ MLflow. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ.\n",
    "\n",
    "–í—ã–ø–æ–ª–Ω–∏–≤ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —à–∞–≥, –≤—ã –ø–æ–ª—É—á–∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π `run_id`. –ù–∏–∂–µ –Ω–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞—à–µ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "qp0g1ixhnc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í –í MLFLOW\n",
      "======================================================================\n",
      "\n",
      "MLflow Tracking URI: http://127.0.0.1:5001\n",
      "Experiment Name: kosmoline_churn_prediction\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å ID: 4\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è S3\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3 –¥–ª—è MLflow\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5001\n",
    "EXPERIMENT_NAME = \"kosmoline_churn_prediction\"\n",
    "RUN_NAME = \"feature_selection_sfs_sbs\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"–õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í –í MLFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nMLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment Name: {EXPERIMENT_NAME}\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º experiment_id\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å ID: {experiment_id}\")\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hebea7ih7z9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Run ID: 0c1b4a8154a64e9f949dba32d1dcaec1\n",
      "‚úÖ Experiment ID: 4\n",
      "‚úÖ Artifact URI: s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/0c1b4a8154a64e9f949dba32d1dcaec1/artifacts\n",
      "\n",
      "üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\n",
      "üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...\n",
      "üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤...\n",
      "  ‚úì –°–æ–∑–¥–∞–Ω sfs.csv\n",
      "  ‚úì –°–æ–∑–¥–∞–Ω sbs.csv\n",
      "  ‚úì –°–æ–∑–¥–∞–Ω sfs.png\n",
      "  ‚úì –°–æ–∑–¥–∞–Ω sbs.png\n",
      "\n",
      "üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MLflow...\n",
      "\n",
      "‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã!\n",
      "\n",
      "üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ 4 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–∞:\n",
      "  - sfs.csv\n",
      "  - sfs.png\n",
      "  - sbs.csv\n",
      "  - sbs.png\n",
      "üèÉ View run feature_selection_sfs_sbs at: http://127.0.0.1:5001/#/experiments/4/runs/0c1b4a8154a64e9f949dba32d1dcaec1\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/4\n",
      "\n",
      "üîó View run: http://127.0.0.1:5001/#/experiments/4/runs/0c1b4a8154a64e9f949dba32d1dcaec1\n",
      "\n",
      "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3...\n",
      "\n",
      "======================================================================\n",
      "–ü–†–û–í–ï–†–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø –í S3\n",
      "======================================================================\n",
      "\n",
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏: s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/0c1b4a8154a64e9f949dba32d1dcaec1/artifacts/\n",
      "\n",
      "‚úÖ –í S3 –Ω–∞–π–¥–µ–Ω–æ 4 —Ñ–∞–π–ª–æ–≤:\n",
      "  ‚úì sbs.csv (181 bytes)\n",
      "  ‚úì sbs.png (33499 bytes)\n",
      "  ‚úì sfs.csv (189 bytes)\n",
      "  ‚úì sfs.png (34111 bytes)\n",
      "\n",
      "üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:\n",
      "  ‚úÖ sfs.csv - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ sfs.png - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ sbs.csv - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ sbs.png - –Ω–∞–π–¥–µ–Ω\n",
      "\n",
      "üéâ –í–°–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –§–ê–ô–õ–´ –ù–ê–ô–î–ï–ù–´!\n",
      "\n",
      "======================================================================\n",
      "‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3\n",
      "======================================================================\n",
      "\n",
      "run_id = \"0c1b4a8154a64e9f949dba32d1dcaec1\"\n",
      "experiment_id = 4\n",
      "\n",
      "–ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º:\n",
      "s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/0c1b4a8154a64e9f949dba32d1dcaec1/artifacts/\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫ MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    print(f\"\\n‚úÖ Run ID: {run_id}\")\n",
    "    print(f\"‚úÖ Experiment ID: {experiment_id}\")\n",
    "    print(f\"‚úÖ Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    print(f\"\\nüìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\")\n",
    "    mlflow.log_param(\"method_1\", \"SFS\")\n",
    "    mlflow.log_param(\"method_2\", \"SBS\")\n",
    "    mlflow.log_param(\"k_features\", 10)\n",
    "    mlflow.log_param(\"cv\", 4)\n",
    "    mlflow.log_param(\"scoring\", \"roc_auc\")\n",
    "    mlflow.log_param(\"estimator\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 300)\n",
    "    mlflow.log_param(\"floating\", False)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    print(f\"üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...\")\n",
    "    mlflow.log_metric(\"sfs_cv_score\", sfs.k_score_)\n",
    "    mlflow.log_metric(\"sbs_cv_score\", sbs.k_score_)\n",
    "    mlflow.log_metric(\"sfs_roc_auc\", roc_auc_sfs)\n",
    "    mlflow.log_metric(\"sbs_roc_auc\", roc_auc_sbs)\n",
    "    mlflow.log_metric(\"all_features_roc_auc\", roc_auc_all)\n",
    "    mlflow.log_metric(\"n_interc_features\", len(interc_features))\n",
    "    mlflow.log_metric(\"n_union_features\", len(union_features))\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n",
    "    print(f\"üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤...\")\n",
    "    \n",
    "    import tempfile\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # 1. –°–æ–∑–¥–∞—ë–º sfs.csv - —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SFS\n",
    "        sfs_csv_file = os.path.join(tmpdir, \"sfs.csv\")\n",
    "        sfs_df = pd.DataFrame({\n",
    "            'feature_name': top_sfs,\n",
    "            'feature_index': [list(X.columns).index(f) for f in top_sfs]\n",
    "        })\n",
    "        sfs_df.to_csv(sfs_csv_file, index=False)\n",
    "        print(f\"  ‚úì –°–æ–∑–¥–∞–Ω sfs.csv\")\n",
    "        \n",
    "        # 2. –°–æ–∑–¥–∞—ë–º sbs.csv - —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SBS\n",
    "        sbs_csv_file = os.path.join(tmpdir, \"sbs.csv\")\n",
    "        sbs_df = pd.DataFrame({\n",
    "            'feature_name': top_sbs,\n",
    "            'feature_index': [list(X.columns).index(f) for f in top_sbs]\n",
    "        })\n",
    "        sbs_df.to_csv(sbs_csv_file, index=False)\n",
    "        print(f\"  ‚úì –°–æ–∑–¥–∞–Ω sbs.csv\")\n",
    "        \n",
    "        # 3. –°–æ–∑–¥–∞—ë–º sfs.png - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SFS\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        y_pos = np.arange(len(top_sfs))\n",
    "        ax.barh(y_pos, [1] * len(top_sfs), color='skyblue')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(top_sfs)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('Selected')\n",
    "        ax.set_title(f'SFS Selected Features (n={len(top_sfs)}, ROC-AUC={sfs.k_score_:.4f})')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        sfs_png_file = os.path.join(tmpdir, \"sfs.png\")\n",
    "        plt.savefig(sfs_png_file, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ‚úì –°–æ–∑–¥–∞–Ω sfs.png\")\n",
    "        \n",
    "        # 4. –°–æ–∑–¥–∞—ë–º sbs.png - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ SBS\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        y_pos = np.arange(len(top_sbs))\n",
    "        ax.barh(y_pos, [1] * len(top_sbs), color='lightcoral')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(top_sbs)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('Selected')\n",
    "        ax.set_title(f'SBS Selected Features (n={len(top_sbs)}, ROC-AUC={sbs.k_score_:.4f})')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        sbs_png_file = os.path.join(tmpdir, \"sbs.png\")\n",
    "        plt.savefig(sbs_png_file, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ‚úì –°–æ–∑–¥–∞–Ω sbs.png\")\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –Ω–∞–ø—Ä—è–º—É—é –≤ artifacts/ (–±–µ–∑ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)\n",
    "        print(f\"\\nüì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MLflow...\")\n",
    "        mlflow.log_artifacts(tmpdir)\n",
    "        \n",
    "    print(f\"\\n‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã!\")\n",
    "    print(f\"\\nüìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ 4 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–∞:\")\n",
    "    print(f\"  - sfs.csv\")\n",
    "    print(f\"  - sfs.png\")\n",
    "    print(f\"  - sbs.csv\")\n",
    "    print(f\"  - sbs.png\")\n",
    "\n",
    "print(f\"\\nüîó View run: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ S3\n",
    "import time\n",
    "print(f\"\\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3...\")\n",
    "time.sleep(5)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"–ü–†–û–í–ï–†–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø –í S3\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "    \n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=os.environ.get('MLFLOW_S3_ENDPOINT_URL'),\n",
    "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "        region_name='ru-central1'\n",
    "    )\n",
    "    \n",
    "    bucket_name = os.getenv('S3_BUCKET_NAME')\n",
    "    prefix = f\"{experiment_id}/{run_id}/artifacts/\"\n",
    "    \n",
    "    print(f\"\\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏: s3://{bucket_name}/{prefix}\")\n",
    "    \n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    \n",
    "    if 'Contents' in response:\n",
    "        print(f\"\\n‚úÖ –í S3 –Ω–∞–π–¥–µ–Ω–æ {len(response['Contents'])} —Ñ–∞–π–ª–æ–≤:\")\n",
    "        \n",
    "        required_files = ['sfs.csv', 'sfs.png', 'sbs.csv', 'sbs.png']\n",
    "        found_files = [obj['Key'].split('/')[-1] for obj in response['Contents']]\n",
    "        \n",
    "        for obj in response['Contents']:\n",
    "            file_name = obj['Key'].split('/')[-1]\n",
    "            if file_name:\n",
    "                print(f\"  ‚úì {file_name} ({obj['Size']} bytes)\")\n",
    "        \n",
    "        print(f\"\\nüìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
    "        all_found = True\n",
    "        for req_file in required_files:\n",
    "            if req_file in found_files:\n",
    "                print(f\"  ‚úÖ {req_file} - –Ω–∞–π–¥–µ–Ω\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {req_file} - –ù–ï –Ω–∞–π–¥–µ–Ω\")\n",
    "                all_found = False\n",
    "        \n",
    "        if all_found:\n",
    "            print(f\"\\nüéâ –í–°–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –§–ê–ô–õ–´ –ù–ê–ô–î–ï–ù–´!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ –ø—É—Ç–∏ {prefix}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ S3: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º run_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "feature_selection_run_id = run_id\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3\")\n",
    "print(\"=\"*70)\n",
    "print(f'\\nrun_id = \"{feature_selection_run_id}\"')\n",
    "print(f'experiment_id = {experiment_id}')\n",
    "print(f'\\n–ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º:')\n",
    "print(f's3://{bucket_name}/{experiment_id}/{run_id}/artifacts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "l0ebtlqx8zl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ –ó–ù–ê–ß–ï–ù–ò–ï –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3\n",
      "======================================================================\n",
      "\n",
      "run_id = \"0c1b4a8154a64e9f949dba32d1dcaec1\"\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–¥–∞–Ω–∏–µ 3: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "run_id = feature_selection_run_id\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ –ó–ù–ê–ß–ï–ù–ò–ï –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3\")\n",
    "print(\"=\"*70)\n",
    "print(f'\\nrun_id = \"{run_id}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v3a5cx7jwvh",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 4\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –æ–±—É—á–∏—Ç–µ –¥–≤–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–≤—É—Ö –Ω–∞–±–æ—Ä–∞—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏. \n",
    "\n",
    "–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –æ–±–µ –º–æ–¥–µ–ª–∏ –≤ MLflow –≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö:\n",
    "- `feature_selection_union` - –¥–ª—è –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "- `feature_selection_intersection` - –¥–ª—è –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–µ—Ä–µ—Å–µ—á—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "\n",
    "–í –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∏–∂–µ –≤—Å—Ç–∞–≤—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "kxfk5ct0xib",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–ó–ê–î–ê–ù–ò–ï 4: –û–ë–£–ß–ï–ù–ò–ï –ò –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ –ú–û–î–ï–õ–¨ –ù–ê –ü–ï–†–ï–°–ï–ß–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–• (INTERSECTION)\n",
      "======================================================================\n",
      "\n",
      "–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 7\n",
      "–ü—Ä–∏–∑–Ω–∞–∫–∏: ['internet_service', 'monthly_charges', 'online_backup', 'paperless_billing', 'payment_method', 'total_charges', 'type']\n",
      "X_train shape: (5634, 7)\n",
      "X_test shape: (1409, 7)\n",
      "\n",
      "ü§ñ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier...\n",
      "\n",
      "üìä –ú–µ—Ç—Ä–∏–∫–∏:\n",
      "  ROC-AUC: 0.8158\n",
      "  Accuracy: 0.7835\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ –ú–û–î–ï–õ–¨ –ù–ê –û–ë–™–ï–î–ò–ù–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–• (UNION)\n",
      "======================================================================\n",
      "\n",
      "–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 13\n",
      "–ü—Ä–∏–∑–Ω–∞–∫–∏: ['gender', 'internet_service', 'monthly_charges', 'online_backup', 'online_security', 'paperless_billing', 'partner', 'payment_method', 'streaming_movies', 'streaming_tv', 'tech_support', 'total_charges', 'type']\n",
      "X_train shape: (5634, 13)\n",
      "X_test shape: (1409, 13)\n",
      "\n",
      "ü§ñ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier...\n",
      "\n",
      "üìä –ú–µ—Ç—Ä–∏–∫–∏:\n",
      "  ROC-AUC: 0.8324\n",
      "  Accuracy: 0.7928\n",
      "\n",
      "\n",
      "üìä –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô\n",
      "======================================================================\n",
      "\n",
      "–ú–æ–¥–µ–ª—å            | –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ | ROC-AUC  | Accuracy\n",
      "------------------------------------------------------------\n",
      "Intersection      |         7 | 0.8158   | 0.7835\n",
      "Union             |        13 | 0.8324   | 0.7928\n",
      "\n",
      "‚úÖ –û–±–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"–ó–ê–î–ê–ù–ò–ï 4: –û–ë–£–ß–ï–ù–ò–ï –ò –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "REGISTRY_MODEL_NAME = \"churn-classifier-feature-selection\"\n",
    "\n",
    "# 1. –ú–û–î–ï–õ–¨ –ù–ê –ü–ï–†–ï–°–ï–ß–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–•\n",
    "print(\"\\n1Ô∏è‚É£ –ú–û–î–ï–õ–¨ –ù–ê –ü–ï–†–ï–°–ï–ß–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–• (INTERSECTION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train_interc = X_train[interc_features]\n",
    "X_test_interc = X_test[interc_features]\n",
    "\n",
    "print(f\"\\n–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(interc_features)}\")\n",
    "print(f\"–ü—Ä–∏–∑–Ω–∞–∫–∏: {interc_features}\")\n",
    "print(f\"X_train shape: {X_train_interc.shape}\")\n",
    "print(f\"X_test shape: {X_test_interc.shape}\")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "print(f\"\\nü§ñ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier...\")\n",
    "model_interc = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model_interc.fit(X_train_interc, y_train)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_pred_interc = model_interc.predict(X_test_interc)\n",
    "y_proba_interc = model_interc.predict_proba(X_test_interc)[:, 1]\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "metrics_interc = {\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_proba_interc),\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_interc)\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä –ú–µ—Ç—Ä–∏–∫–∏:\")\n",
    "print(f\"  ROC-AUC: {metrics_interc['roc_auc']:.4f}\")\n",
    "print(f\"  Accuracy: {metrics_interc['accuracy']:.4f}\")\n",
    "\n",
    "# 2. –ú–û–î–ï–õ–¨ –ù–ê –û–ë–™–ï–î–ò–ù–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–•\n",
    "print(f\"\\n\\n2Ô∏è‚É£ –ú–û–î–ï–õ–¨ –ù–ê –û–ë–™–ï–î–ò–ù–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–• (UNION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train_union = X_train[union_features]\n",
    "X_test_union = X_test[union_features]\n",
    "\n",
    "print(f\"\\n–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(union_features)}\")\n",
    "print(f\"–ü—Ä–∏–∑–Ω–∞–∫–∏: {union_features}\")\n",
    "print(f\"X_train shape: {X_train_union.shape}\")\n",
    "print(f\"X_test shape: {X_test_union.shape}\")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "print(f\"\\nü§ñ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier...\")\n",
    "model_union = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model_union.fit(X_train_union, y_train)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_pred_union = model_union.predict(X_test_union)\n",
    "y_proba_union = model_union.predict_proba(X_test_union)[:, 1]\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "metrics_union = {\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_proba_union),\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_union)\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä –ú–µ—Ç—Ä–∏–∫–∏:\")\n",
    "print(f\"  ROC-AUC: {metrics_union['roc_auc']:.4f}\")\n",
    "print(f\"  Accuracy: {metrics_union['accuracy']:.4f}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "print(f\"\\n\\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n–ú–æ–¥–µ–ª—å            | –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ | ROC-AUC  | Accuracy\")\n",
    "print(f\"-\" * 60)\n",
    "print(f\"Intersection      | {len(interc_features):9} | {metrics_interc['roc_auc']:.4f}   | {metrics_interc['accuracy']:.4f}\")\n",
    "print(f\"Union             | {len(union_features):9} | {metrics_union['roc_auc']:.4f}   | {metrics_union['accuracy']:.4f}\")\n",
    "print(f\"\\n‚úÖ –û–±–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "325hyja34cr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "–†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô –í MLFLOW\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò INTERSECTION –í MLFLOW\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 17:57:59 INFO mlflow.tracking.fluent: Experiment with name 'feature_selection_intersection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: feature_selection_intersection\n",
      "Experiment ID: 6\n",
      "\n",
      "Run ID: 2d80df5ecaea4c5989b6ea25e59478fe\n",
      "Run Name: intersection_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 17:58:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ 'churn-classifier-feature-selection'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asvorobyev/miniconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Users/asvorobyev/miniconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'churn-classifier-feature-selection'.\n",
      "2025/12/07 18:01:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: churn-classifier-feature-selection, version 1\n",
      "Created version '1' of model 'churn-classifier-feature-selection'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!\n",
      "   Model URI: models:/m-765d35fe73c64fab9e0b1c81a579ea6f\n",
      "üèÉ View run intersection_model at: http://127.0.0.1:5001/#/experiments/6/runs/2d80df5ecaea4c5989b6ea25e59478fe\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/6\n",
      "\n",
      "üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ INTERSECTION:\n",
      "   Registered Model Name: churn-classifier-feature-selection\n",
      "   Model Version: 1\n",
      "   Run Name: intersection_model\n",
      "   Run ID: 2d80df5ecaea4c5989b6ea25e59478fe\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò UNION –í MLFLOW\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 18:01:50 INFO mlflow.tracking.fluent: Experiment with name 'feature_selection_union' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: feature_selection_union\n",
      "Experiment ID: 7\n",
      "\n",
      "Run ID: 303f6ad64ee744c9ae216bd3e99758c9\n",
      "Run Name: union_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 18:02:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ 'churn-classifier-feature-selection'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asvorobyev/miniconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Users/asvorobyev/miniconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'churn-classifier-feature-selection' already exists. Creating a new version of this model...\n",
      "2025/12/07 18:07:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: churn-classifier-feature-selection, version 2\n",
      "Created version '2' of model 'churn-classifier-feature-selection'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!\n",
      "   Model URI: models:/m-b3847ac2c09c4f69ad7f709ffd8b4291\n",
      "üèÉ View run union_model at: http://127.0.0.1:5001/#/experiments/7/runs/303f6ad64ee744c9ae216bd3e99758c9\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/7\n",
      "\n",
      "üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ UNION:\n",
      "   Registered Model Name: churn-classifier-feature-selection\n",
      "   Model Version: 2\n",
      "   Run Name: union_model\n",
      "   Run ID: 303f6ad64ee744c9ae216bd3e99758c9\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–†–ï–ì–ò–°–¢–†–ò–†–û–í–ê–ù–ù–´–• –ú–û–î–ï–õ–ï–ô\n",
      "======================================================================\n",
      "\n",
      "        Model  Features  ROC-AUC  Accuracy  Version                           Run ID\n",
      "Intersection         7 0.815764  0.783534        1 2d80df5ecaea4c5989b6ea25e59478fe\n",
      "       Union        13 0.832437  0.792761        2 303f6ad64ee744c9ae216bd3e99758c9\n",
      "\n",
      "‚úÖ –û–±–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ MLflow!\n",
      "\n",
      "üîó View Models: http://127.0.0.1:5001/#/models/churn-classifier-feature-selection\n"
     ]
    }
   ],
   "source": [
    "# –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô –í MLFLOW\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô –í MLFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "registred_model_name = \"churn-classifier-feature-selection\"\n",
    "\n",
    "# 1. –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –ù–ê –ü–ï–†–ï–°–ï–ß–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–•\n",
    "print(\"\\n1Ô∏è‚É£ –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò INTERSECTION –í MLFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º/–ø–æ–ª—É—á–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "EXPERIMENT_NAME_INTERC = \"feature_selection_intersection\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_INTERC)\n",
    "\n",
    "experiment_interc = mlflow.get_experiment_by_name(EXPERIMENT_NAME_INTERC)\n",
    "experiment_id_interc = experiment_interc.experiment_id\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME_INTERC}\")\n",
    "print(f\"Experiment ID: {experiment_id_interc}\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º run –∏ –ª–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "with mlflow.start_run(run_name=\"intersection_model\", experiment_id=experiment_id_interc) as run:\n",
    "    run_id_interc = run.info.run_id\n",
    "    run_name_interc = run.info.run_name\n",
    "    \n",
    "    print(f\"\\nRun ID: {run_id_interc}\")\n",
    "    print(f\"Run Name: {run_name_interc}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_param(\"n_features\", len(interc_features))\n",
    "    mlflow.log_param(\"features\", \", \".join(interc_features))\n",
    "    mlflow.log_param(\"feature_selection_method\", \"intersection_sfs_sbs\")\n",
    "    mlflow.log_param(\"n_estimators\", 300)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metric(\"roc_auc\", metrics_interc['roc_auc'])\n",
    "    mlflow.log_metric(\"accuracy\", metrics_interc['accuracy'])\n",
    "    mlflow.log_metric(\"test_size\", X_test_interc.shape[0])\n",
    "    mlflow.log_metric(\"train_size\", X_train_interc.shape[0])\n",
    "    \n",
    "    # –°–æ–∑–¥–∞—ë–º –∏ –ª–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n",
    "    import tempfile\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        features_file = os.path.join(tmpdir, \"features.txt\")\n",
    "        with open(features_file, 'w') as f:\n",
    "            f.write(\"Features used in intersection model:\\n\")\n",
    "            f.write(\"\\n\".join(interc_features))\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': interc_features,\n",
    "            'importance': model_interc.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_title(f'Feature Importances (Intersection Model)\\nROC-AUC: {metrics_interc[\"roc_auc\"]:.4f}')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        importance_file = os.path.join(tmpdir, \"feature_importance.png\")\n",
    "        plt.savefig(importance_file, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n",
    "        mlflow.log_artifacts(tmpdir)\n",
    "    \n",
    "    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    print(f\"\\nüì¶ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ '{registred_model_name}'...\")\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model_interc,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=registred_model_name,\n",
    "        input_example=X_train_interc[:5]\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!\")\n",
    "    print(f\"   Model URI: {model_info.model_uri}\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "model_versions = client.search_model_versions(f\"name='{registred_model_name}'\")\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ run_id\n",
    "model_version_id_interc = None\n",
    "for mv in model_versions:\n",
    "    if mv.run_id == run_id_interc:\n",
    "        model_version_id_interc = int(mv.version)\n",
    "        break\n",
    "\n",
    "print(f\"\\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ INTERSECTION:\")\n",
    "print(f\"   Registered Model Name: {registred_model_name}\")\n",
    "print(f\"   Model Version: {model_version_id_interc}\")\n",
    "print(f\"   Run Name: {run_name_interc}\")\n",
    "print(f\"   Run ID: {run_id_interc}\")\n",
    "\n",
    "# 2. –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –ù–ê –û–ë–™–ï–î–ò–ù–Å–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–ê–•\n",
    "print(\"\\n\\n2Ô∏è‚É£ –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò UNION –í MLFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º/–ø–æ–ª—É—á–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "EXPERIMENT_NAME_UNION = \"feature_selection_union\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_UNION)\n",
    "\n",
    "experiment_union = mlflow.get_experiment_by_name(EXPERIMENT_NAME_UNION)\n",
    "experiment_id_union = experiment_union.experiment_id\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME_UNION}\")\n",
    "print(f\"Experiment ID: {experiment_id_union}\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º run –∏ –ª–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "with mlflow.start_run(run_name=\"union_model\", experiment_id=experiment_id_union) as run:\n",
    "    run_id_union = run.info.run_id\n",
    "    run_name_union = run.info.run_name\n",
    "    \n",
    "    print(f\"\\nRun ID: {run_id_union}\")\n",
    "    print(f\"Run Name: {run_name_union}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_param(\"n_features\", len(union_features))\n",
    "    mlflow.log_param(\"features\", \", \".join(union_features))\n",
    "    mlflow.log_param(\"feature_selection_method\", \"union_sfs_sbs\")\n",
    "    mlflow.log_param(\"n_estimators\", 300)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metric(\"roc_auc\", metrics_union['roc_auc'])\n",
    "    mlflow.log_metric(\"accuracy\", metrics_union['accuracy'])\n",
    "    mlflow.log_metric(\"test_size\", X_test_union.shape[0])\n",
    "    mlflow.log_metric(\"train_size\", X_train_union.shape[0])\n",
    "    \n",
    "    # –°–æ–∑–¥–∞—ë–º –∏ –ª–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        features_file = os.path.join(tmpdir, \"features.txt\")\n",
    "        with open(features_file, 'w') as f:\n",
    "            f.write(\"Features used in union model:\\n\")\n",
    "            f.write(\"\\n\".join(union_features))\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': union_features,\n",
    "            'importance': model_union.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.barh(feature_importance['feature'], feature_importance['importance'], color='coral')\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_title(f'Feature Importances (Union Model)\\nROC-AUC: {metrics_union[\"roc_auc\"]:.4f}')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        importance_file = os.path.join(tmpdir, \"feature_importance.png\")\n",
    "        plt.savefig(importance_file, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n",
    "        mlflow.log_artifacts(tmpdir)\n",
    "    \n",
    "    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    print(f\"\\nüì¶ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ '{registred_model_name}'...\")\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model_union,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=registred_model_name,\n",
    "        input_example=X_train_union[:5]\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!\")\n",
    "    print(f\"   Model URI: {model_info.model_uri}\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏\n",
    "model_versions = client.search_model_versions(f\"name='{registred_model_name}'\")\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ run_id\n",
    "model_version_id_union = None\n",
    "for mv in model_versions:\n",
    "    if mv.run_id == run_id_union:\n",
    "        model_version_id_union = int(mv.version)\n",
    "        break\n",
    "\n",
    "print(f\"\\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ UNION:\")\n",
    "print(f\"   Registered Model Name: {registred_model_name}\")\n",
    "print(f\"   Model Version: {model_version_id_union}\")\n",
    "print(f\"   Run Name: {run_name_union}\")\n",
    "print(f\"   Run ID: {run_id_union}\")\n",
    "\n",
    "# –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"üìä –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–†–ï–ì–ò–°–¢–†–ò–†–û–í–ê–ù–ù–´–• –ú–û–î–ï–õ–ï–ô\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Intersection', 'Union'],\n",
    "    'Features': [len(interc_features), len(union_features)],\n",
    "    'ROC-AUC': [metrics_interc['roc_auc'], metrics_union['roc_auc']],\n",
    "    'Accuracy': [metrics_interc['accuracy'], metrics_union['accuracy']],\n",
    "    'Version': [model_version_id_interc, model_version_id_union],\n",
    "    'Run ID': [run_id_interc, run_id_union]\n",
    "})\n",
    "\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n‚úÖ –û–±–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ MLflow!\")\n",
    "print(f\"\\nüîó View Models: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}/#/models/{registred_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bttuql7iotk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ –ó–ê–î–ê–ù–ò–ï 4: –§–ò–ù–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –ü–†–û–í–ï–†–ö–ò\n",
      "======================================================================\n",
      "\n",
      "registred_model_name = 'churn-classifier-feature-selection'\n",
      "\n",
      "# –ú–æ–¥–µ–ª—å –Ω–∞ –ø–µ—Ä–µ—Å–µ—á—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö:\n",
      "model_version_id_interc = 1  # –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
      "run_name_interc = \"intersection_model\"  # –Ω–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
      "run_id_interc = \"2d80df5ecaea4c5989b6ea25e59478fe\"  # run_id\n",
      "\n",
      "# –ú–æ–¥–µ–ª—å –Ω–∞ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö:\n",
      "model_version_id_union = 2  # –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
      "run_name_union = \"union_model\"  # –Ω–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
      "run_id_union = \"303f6ad64ee744c9ae216bd3e99758c9\"  # run_id\n",
      "\n",
      "======================================================================\n",
      "–î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–Ø–•\n",
      "======================================================================\n",
      "\n",
      "üì¶ –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: churn-classifier-feature-selection\n",
      "\n",
      "1Ô∏è‚É£ –ú–æ–¥–µ–ª—å INTERSECTION:\n",
      "   - –í–µ—Ä—Å–∏—è: 1\n",
      "   - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: feature_selection_intersection\n",
      "   - Run Name: intersection_model\n",
      "   - Run ID: 2d80df5ecaea4c5989b6ea25e59478fe\n",
      "   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 7\n",
      "   - ROC-AUC: 0.8158\n",
      "   - Accuracy: 0.7835\n",
      "\n",
      "2Ô∏è‚É£ –ú–æ–¥–µ–ª—å UNION:\n",
      "   - –í–µ—Ä—Å–∏—è: 2\n",
      "   - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: feature_selection_union\n",
      "   - Run Name: union_model\n",
      "   - Run ID: 303f6ad64ee744c9ae216bd3e99758c9\n",
      "   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: 13\n",
      "   - ROC-AUC: 0.8324\n",
      "   - Accuracy: 0.7928\n",
      "\n",
      "======================================================================\n",
      "‚úÖ –ó–ê–î–ê–ù–ò–ï 4 –í–´–ü–û–õ–ù–ï–ù–û!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# –ó–ê–î–ê–ù–ò–ï 4: –§–ò–ù–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –ü–†–û–í–ï–†–ö–ò\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ –ó–ê–î–ê–ù–ò–ï 4: –§–ò–ù–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –ü–†–û–í–ï–†–ö–ò\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –¥–ª—è –æ–±–µ–∏—Ö –≤–µ—Ä—Å–∏–π)\n",
    "print(f\"\\nregistred_model_name = '{registred_model_name}'\")\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å –Ω–∞ –ø–µ—Ä–µ—Å–µ—á—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (INTERSECTION)\n",
    "print(f\"\\n# –ú–æ–¥–µ–ª—å –Ω–∞ –ø–µ—Ä–µ—Å–µ—á—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö:\")\n",
    "print(f\"model_version_id_interc = {model_version_id_interc}  # –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\")\n",
    "print(f'run_name_interc = \"{run_name_interc}\"  # –Ω–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞')\n",
    "print(f'run_id_interc = \"{run_id_interc}\"  # run_id')\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å –Ω–∞ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (UNION)\n",
    "print(f\"\\n# –ú–æ–¥–µ–ª—å –Ω–∞ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö:\")\n",
    "print(f\"model_version_id_union = {model_version_id_union}  # –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\")\n",
    "print(f'run_name_union = \"{run_name_union}\"  # –Ω–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞')\n",
    "print(f'run_id_union = \"{run_id_union}\"  # run_id')\n",
    "\n",
    "# –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–Ø–•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüì¶ –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {registred_model_name}\")\n",
    "print(f\"\\n1Ô∏è‚É£ –ú–æ–¥–µ–ª—å INTERSECTION:\")\n",
    "print(f\"   - –í–µ—Ä—Å–∏—è: {model_version_id_interc}\")\n",
    "print(f\"   - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: feature_selection_intersection\")\n",
    "print(f\"   - Run Name: {run_name_interc}\")\n",
    "print(f\"   - Run ID: {run_id_interc}\")\n",
    "print(f\"   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(interc_features)}\")\n",
    "print(f\"   - ROC-AUC: {metrics_interc['roc_auc']:.4f}\")\n",
    "print(f\"   - Accuracy: {metrics_interc['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ –ú–æ–¥–µ–ª—å UNION:\")\n",
    "print(f\"   - –í–µ—Ä—Å–∏—è: {model_version_id_union}\")\n",
    "print(f\"   - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: feature_selection_union\")\n",
    "print(f\"   - Run Name: {run_name_union}\")\n",
    "print(f\"   - Run ID: {run_id_union}\")\n",
    "print(f\"   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(union_features)}\")\n",
    "print(f\"   - ROC-AUC: {metrics_union['roc_auc']:.4f}\")\n",
    "print(f\"   - Accuracy: {metrics_union['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ –ó–ê–î–ê–ù–ò–ï 4 –í–´–ü–û–õ–ù–ï–ù–û!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## –ò—Ç–æ–≥–∏\n",
    "\n",
    "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –º—ã:\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ** –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö users_churn\n",
    "2. **–ü–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ** - –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "3. **–ü—Ä–∏–º–µ–Ω–∏–ª–∏ SFS** (Sequential Forward Selection) –¥–ª—è –æ—Ç–±–æ—Ä–∞ 10 –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "4. **–ü—Ä–∏–º–µ–Ω–∏–ª–∏ SBS** (Sequential Backward Selection) –¥–ª—è –æ—Ç–±–æ—Ä–∞ 10 –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "5. **–°—Ä–∞–≤–Ω–∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –æ–±–æ–∏—Ö –º–µ—Ç–æ–¥–æ–≤\n",
    "6. **–û–±—É—á–∏–ª–∏ –º–æ–¥–µ–ª–∏** –Ω–∞ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –∏ —Å—Ä–∞–≤–Ω–∏–ª–∏ —Å –º–æ–¥–µ–ª—å—é –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "\n",
    "### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "- –û—Ü–µ–Ω—â–∏–∫: RandomForestClassifier (300 –¥–µ—Ä–µ–≤—å–µ–≤)\n",
    "- –ú–µ—Ç—Ä–∏–∫–∞: ROC-AUC\n",
    "- –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: 4 —Ñ–æ–ª–¥–∞\n",
    "- Floating: –≤—ã–∫–ª—é—á–µ–Ω\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–±–∏—Ä–∞–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 10\n",
    "\n",
    "### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏:\n",
    "- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤ SFS –∏ SBS –≤ —Å–Ω–∏–∂–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "- –ö–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
