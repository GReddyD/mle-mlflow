{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "task1_header",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1\n",
    "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ autofeat. \n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏:\n",
    "a. –æ–±—Ä–∞—Ç–Ω–æ–µ –¥–µ–ª–µ–Ω–∏–µ 1/,\n",
    "b. –ø–æ–¥—Å—á—ë—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∞,\n",
    "c. –≤–∑—è—Ç–∏–µ –º–æ–¥—É–ª—è,\n",
    "d. –≤–∑—è—Ç–∏–µ –∫–æ—Ä–Ω—è.\n",
    "–î–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ feateng_steps, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ 1.\n",
    "–î–ª—è n_jobs —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ -1 ‚Äî —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤—Å–µ —è–¥—Ä–∞ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω—ã.\n",
    "–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π X_train, –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–ª—è –Ω–µ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è. –û—Ç–¥–µ–ª—å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –∏–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "data_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: (7043, 22)\n",
      "\n",
      "X_train shape: (5634, 16)\n",
      "X_test shape: (1409, 16)\n",
      "y_train shape: (5634,)\n",
      "y_test shape: (1409,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>...</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>8189</td>\n",
       "      <td>2889-FPWRM</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>117.80</td>\n",
       "      <td>8684.80</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>5869</td>\n",
       "      <td>0917-EZOLA</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>104.15</td>\n",
       "      <td>7689.95</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>7994</td>\n",
       "      <td>8580-QVLOC</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>92.45</td>\n",
       "      <td>6440.25</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>977</td>\n",
       "      <td>2834-JRTUA</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>108.05</td>\n",
       "      <td>7532.15</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>5072</td>\n",
       "      <td>7317-GGVPB</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>108.60</td>\n",
       "      <td>7690.90</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id customer_id begin_date   end_date      type paperless_billing  \\\n",
       "4625  8189  2889-FPWRM 2013-10-01 2019-10-01  One year               Yes   \n",
       "3462  5869  0917-EZOLA 2013-10-01 2019-10-01  Two year               Yes   \n",
       "4527  7994  8580-QVLOC 2013-10-01 2019-10-01  Two year                No   \n",
       "1509   977  2834-JRTUA 2013-11-01 2019-10-01  Two year               Yes   \n",
       "3066  5072  7317-GGVPB 2013-11-01 2019-10-01  Two year               Yes   \n",
       "\n",
       "                 payment_method  monthly_charges  total_charges  \\\n",
       "4625  Bank transfer (automatic)           117.80        8684.80   \n",
       "3462  Bank transfer (automatic)           104.15        7689.95   \n",
       "4527    Credit card (automatic)            92.45        6440.25   \n",
       "1509           Electronic check           108.05        7532.15   \n",
       "3066    Credit card (automatic)           108.60        7690.90   \n",
       "\n",
       "     internet_service  ... device_protection tech_support streaming_tv  \\\n",
       "4625      Fiber optic  ...               Yes          Yes          Yes   \n",
       "3462      Fiber optic  ...               Yes           No          Yes   \n",
       "4527              DSL  ...               Yes          Yes          Yes   \n",
       "1509      Fiber optic  ...               Yes          Yes          Yes   \n",
       "3066      Fiber optic  ...               Yes          Yes          Yes   \n",
       "\n",
       "     streaming_movies  gender senior_citizen partner  dependents  \\\n",
       "4625              Yes    Male              0     Yes          No   \n",
       "3462              Yes    Male              1     Yes          No   \n",
       "4527              Yes  Female              1     Yes         Yes   \n",
       "1509              Yes    Male              0      No          No   \n",
       "3066              Yes    Male              0     Yes          No   \n",
       "\n",
       "     multiple_lines target  \n",
       "4625            Yes      1  \n",
       "3462            Yes      1  \n",
       "4527            Yes      1  \n",
       "1509            Yes      1  \n",
       "3066            Yes      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv('../.env')\n",
    "\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}\")\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "cat_features = [\n",
    "    'paperless_billing',\n",
    "    'payment_method',\n",
    "    'internet_service',\n",
    "    'online_security',\n",
    "    'online_backup',\n",
    "    'device_protection',\n",
    "    'tech_support',\n",
    "    'streaming_tv',\n",
    "    'streaming_movies',\n",
    "    'gender',\n",
    "    'senior_citizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'multiple_lines',\n",
    "]\n",
    "num_features = [\"monthly_charges\", \"total_charges\"]\n",
    "features = cat_features + num_features\n",
    "target = 'target'\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "split_column = \"begin_date\"\n",
    "test_size = 0.2\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features],\n",
    "    df[target],\n",
    "    test_size=test_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "autofeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asvorobyev/miniconda3/lib/python3.12/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 16\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ autofeat: 41\n",
      "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 25\n"
     ]
    }
   ],
   "source": [
    "from autofeat import AutoFeatClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π\n",
    "transformations = ('1/', 'log', 'abs', 'sqrt')\n",
    "\n",
    "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è autofeat\n",
    "# autofeat —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    X_test_encoded[col] = le.transform(X_test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "afc = AutoFeatClassifier(\n",
    "    categorical_cols=cat_features, \n",
    "    transformations=transformations, \n",
    "    feateng_steps=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "X_train_features = afc.fit_transform(X_train_encoded, y_train)\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–∞\n",
    "X_test_features = afc.transform(X_test_encoded)\n",
    "\n",
    "# –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train_encoded.shape[1]}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ autofeat: {X_train_features.shape[1]}\")\n",
    "print(f\"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train_features.shape[1] - X_train_encoded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task2_header",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 2\n",
    "–ß—Ç–æ–±—ã –¥–æ–±–∏—Ç—å—Å—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏, –æ–±—ä–µ–∫—Ç afc –º–æ–∂–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤ MLflow. –î–µ–ª–∞–µ—Ç—Å—è —ç—Ç–æ —Ç–∞–∫:\n",
    "\n",
    "```python\n",
    "artifact_path = \"afc\"\n",
    "experiment_id = mlflow.get_experiment_by_name(\"your experiment name\").experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=\"your run name\", experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    afc_info = mlflow.sklearn.log_model(afc, artifact_path=artifact_path)\n",
    "```\n",
    "\n",
    "–í—Å—Ç–∞–≤—å—Ç–µ run_id –∏ artifact_path —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –æ–±—ä–µ–∫—Ç afc, –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∏–∂–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mlflow_log",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://127.0.0.1:5001\n",
      "Experiment Name: kosmoline_churn_prediction\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å ID: 4\n",
      "\n",
      "‚úÖ Run ID: 739364c47b914c918bd68dae8fa3f46a\n",
      "‚úÖ Experiment ID: 4\n",
      "‚úÖ Artifact URI: s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/739364c47b914c918bd68dae8fa3f46a/artifacts\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ AutoFeatClassifier —á–µ—Ä–µ–∑ log_artifacts...\n",
      "  ‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: /var/folders/6g/s9qby9js2yd4gy8c0t6tftgh0000gp/T/tmpt_1imgsp/afc/model.pkl\n",
      "  ‚úì MLmodel —Å–æ–∑–¥–∞–Ω: /var/folders/6g/s9qby9js2yd4gy8c0t6tftgh0000gp/T/tmpt_1imgsp/afc/MLmodel\n",
      "  ‚úì requirements.txt —Å–æ–∑–¥–∞–Ω: /var/folders/6g/s9qby9js2yd4gy8c0t6tftgh0000gp/T/tmpt_1imgsp/afc/requirements.txt\n",
      "  ‚úì conda.yaml —Å–æ–∑–¥–∞–Ω: /var/folders/6g/s9qby9js2yd4gy8c0t6tftgh0000gp/T/tmpt_1imgsp/afc/conda.yaml\n",
      "  ‚úì python_env.yaml —Å–æ–∑–¥–∞–Ω: /var/folders/6g/s9qby9js2yd4gy8c0t6tftgh0000gp/T/tmpt_1imgsp/afc/python_env.yaml\n",
      "\n",
      "üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MLflow...\n",
      "‚úÖ AutoFeatClassifier —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω!\n",
      "Artifact path: afc\n",
      "üèÉ View run autofeat_feature_generation at: http://127.0.0.1:5001/#/experiments/4/runs/739364c47b914c918bd68dae8fa3f46a\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/4\n",
      "\n",
      "üîó View run: http://127.0.0.1:5001/#/experiments/4/runs/739364c47b914c918bd68dae8fa3f46a\n",
      "\n",
      "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3...\n",
      "\n",
      "======================================================================\n",
      "–ü–†–û–í–ï–†–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø –í S3\n",
      "======================================================================\n",
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏: s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/\n",
      "\n",
      "‚úÖ –í S3 –Ω–∞–π–¥–µ–Ω–æ 5 —Ñ–∞–π–ª–æ–≤:\n",
      "  ‚úì 4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/MLmodel (527 bytes)\n",
      "  ‚úì 4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/conda.yaml (169 bytes)\n",
      "  ‚úì 4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/model.pkl (12584 bytes)\n",
      "  ‚úì 4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/python_env.yaml (104 bytes)\n",
      "  ‚úì 4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/requirements.txt (42 bytes)\n",
      "\n",
      "üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:\n",
      "  ‚úÖ requirements.txt - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ python_env.yaml - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ MLmodel - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ model.pkl - –Ω–∞–π–¥–µ–Ω\n",
      "  ‚úÖ conda.yaml - –Ω–∞–π–¥–µ–Ω\n",
      "\n",
      "üéâ –í–°–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –§–ê–ô–õ–´ –ù–ê–ô–î–ï–ù–´!\n",
      "\n",
      "======================================================================\n",
      "üìù –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø:\n",
      "======================================================================\n",
      "bucket_name = \"s3-student-mle-20250507-39f5f3ff21-freetrack\"\n",
      "experiment_id = 4\n",
      "run_id = \"739364c47b914c918bd68dae8fa3f46a\"\n",
      "artifact_path = \"afc\"\n",
      "\n",
      "–ü–æ–ª–Ω—ã–π –ø—É—Ç—å: s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import tempfile\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è S3\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3 –¥–ª—è MLflow\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5001\n",
    "EXPERIMENT_NAME = \"kosmoline_churn_prediction\"\n",
    "RUN_NAME = \"autofeat_feature_generation\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment Name: {EXPERIMENT_NAME}\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º experiment_id\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å ID: {experiment_id}\")\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å ID: {experiment_id}\")\n",
    "\n",
    "# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ afc –≤ MLflow\n",
    "artifact_path = \"afc\"\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    artifact_uri = run.info.artifact_uri\n",
    "    \n",
    "    print(f\"\\n‚úÖ Run ID: {run_id}\")\n",
    "    print(f\"‚úÖ Experiment ID: {experiment_id}\")\n",
    "    print(f\"‚úÖ Artifact URI: {artifact_uri}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_param(\"transformations\", str(transformations))\n",
    "    mlflow.log_param(\"feateng_steps\", 1)\n",
    "    mlflow.log_param(\"n_features_original\", X_train_encoded.shape[1])\n",
    "    mlflow.log_param(\"n_features_generated\", X_train_features.shape[1])\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metric(\"features_added\", X_train_features.shape[1] - X_train_encoded.shape[1])\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–∫—Ç afc —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "    print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ AutoFeatClassifier —á–µ—Ä–µ–∑ log_artifacts...\")\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # –°–æ–∑–¥–∞—ë–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞\n",
    "        artifact_dir = os.path.join(tmpdir, artifact_path)\n",
    "        os.makedirs(artifact_dir, exist_ok=True)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ sklearn\n",
    "        model_path = os.path.join(artifact_dir, \"model.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(afc, f)\n",
    "        print(f\"  ‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º MLmodel —Ñ–∞–π–ª\n",
    "        mlmodel_content = f\"\"\"artifact_path: {artifact_path}\n",
    "flavors:\n",
    "  python_function:\n",
    "    env:\n",
    "      conda: conda.yaml\n",
    "      virtualenv: python_env.yaml\n",
    "    loader_module: mlflow.sklearn\n",
    "    model_path: model.pkl\n",
    "    predict_fn: transform\n",
    "    python_version: 3.12.7\n",
    "  sklearn:\n",
    "    code: null\n",
    "    pickled_model: model.pkl\n",
    "    serialization_format: cloudpickle\n",
    "    sklearn_version: 1.5.2\n",
    "mlflow_version: 2.18.0\n",
    "model_size_bytes: {os.path.getsize(model_path)}\n",
    "model_uuid: {run_id}\n",
    "run_id: {run_id}\n",
    "utc_time_created: '2025-12-07 13:27:48.123456'\n",
    "\"\"\"\n",
    "        mlmodel_path = os.path.join(artifact_dir, \"MLmodel\")\n",
    "        with open(mlmodel_path, 'w') as f:\n",
    "            f.write(mlmodel_content)\n",
    "        print(f\"  ‚úì MLmodel —Å–æ–∑–¥–∞–Ω: {mlmodel_path}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º requirements.txt\n",
    "        requirements_content = \"\"\"scikit-learn==1.5.2\n",
    "autofeat\n",
    "pandas\n",
    "numpy\n",
    "\"\"\"\n",
    "        requirements_path = os.path.join(artifact_dir, \"requirements.txt\")\n",
    "        with open(requirements_path, 'w') as f:\n",
    "            f.write(requirements_content)\n",
    "        print(f\"  ‚úì requirements.txt —Å–æ–∑–¥–∞–Ω: {requirements_path}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º conda.yaml\n",
    "        conda_content = \"\"\"channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.12.7\n",
    "- pip<=24.2\n",
    "- pip:\n",
    "  - mlflow==2.18.0\n",
    "  - cloudpickle==3.1.0\n",
    "  - scikit-learn==1.5.2\n",
    "  - autofeat\n",
    "name: mlflow-env\n",
    "\"\"\"\n",
    "        conda_path = os.path.join(artifact_dir, \"conda.yaml\")\n",
    "        with open(conda_path, 'w') as f:\n",
    "            f.write(conda_content)\n",
    "        print(f\"  ‚úì conda.yaml —Å–æ–∑–¥–∞–Ω: {conda_path}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º python_env.yaml\n",
    "        python_env_content = \"\"\"python: 3.12.7\n",
    "build_dependencies:\n",
    "- pip==24.2\n",
    "- setuptools\n",
    "- wheel\n",
    "dependencies:\n",
    "- -r requirements.txt\n",
    "\"\"\"\n",
    "        python_env_path = os.path.join(artifact_dir, \"python_env.yaml\")\n",
    "        with open(python_env_path, 'w') as f:\n",
    "            f.write(python_env_content)\n",
    "        print(f\"  ‚úì python_env.yaml —Å–æ–∑–¥–∞–Ω: {python_env_path}\")\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç\n",
    "        print(f\"\\nüì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MLflow...\")\n",
    "        mlflow.log_artifacts(tmpdir)\n",
    "    \n",
    "    print(f\"‚úÖ AutoFeatClassifier —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω!\")\n",
    "    print(f\"Artifact path: {artifact_path}\")\n",
    "\n",
    "print(f\"\\nüîó View run: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "# –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3\n",
    "print(\"\\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ S3\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–ü–†–û–í–ï–†–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø –í S3\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "    \n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=os.environ.get('MLFLOW_S3_ENDPOINT_URL'),\n",
    "        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "        region_name='ru-central1'\n",
    "    )\n",
    "    \n",
    "    bucket_name = os.getenv('S3_BUCKET_NAME')\n",
    "    prefix = f\"{experiment_id}/{run_id}/artifacts/{artifact_path}/\"\n",
    "    \n",
    "    print(f\"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏: s3://{bucket_name}/{prefix}\")\n",
    "    \n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    \n",
    "    if 'Contents' in response and len(response['Contents']) > 0:\n",
    "        print(f\"\\n‚úÖ –í S3 –Ω–∞–π–¥–µ–Ω–æ {len(response['Contents'])} —Ñ–∞–π–ª–æ–≤:\")\n",
    "        \n",
    "        required_files = ['requirements.txt', 'python_env.yaml', 'MLmodel', 'model.pkl', 'conda.yaml']\n",
    "        found_files = []\n",
    "        \n",
    "        for obj in response['Contents']:\n",
    "            file_name = obj['Key'].split('/')[-1]\n",
    "            if file_name:\n",
    "                found_files.append(file_name)\n",
    "                print(f\"  ‚úì {obj['Key']} ({obj['Size']} bytes)\")\n",
    "        \n",
    "        print(f\"\\nüìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
    "        all_found = True\n",
    "        for req_file in required_files:\n",
    "            if req_file in found_files:\n",
    "                print(f\"  ‚úÖ {req_file} - –Ω–∞–π–¥–µ–Ω\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {req_file} - –ù–ï –Ω–∞–π–¥–µ–Ω\")\n",
    "                all_found = False\n",
    "        \n",
    "        if all_found:\n",
    "            print(f\"\\nüéâ –í–°–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –§–ê–ô–õ–´ –ù–ê–ô–î–ï–ù–´!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ –ø—É—Ç–∏ {prefix}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ S3: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–¥–∞–Ω–∏—è\n",
    "afc_run_id = run_id\n",
    "afc_artifact_path = artifact_path\n",
    "afc_experiment_id = experiment_id\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìù –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø:\")\n",
    "print(\"=\"*70)\n",
    "print(f'bucket_name = \"{bucket_name}\"')\n",
    "print(f'experiment_id = {afc_experiment_id}')\n",
    "print(f'run_id = \"{afc_run_id}\"')\n",
    "print(f'artifact_path = \"{afc_artifact_path}\"')\n",
    "print(f'\\n–ü–æ–ª–Ω—ã–π –ø—É—Ç—å: s3://{bucket_name}/{afc_experiment_id}/{afc_run_id}/artifacts/{afc_artifact_path}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "task2_answer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 2\n",
      "======================================================================\n",
      "bucket_name = \"s3-student-mle-20250507-39f5f3ff21-freetrack\"\n",
      "experiment_id = 4\n",
      "run_id = \"739364c47b914c918bd68dae8fa3f46a\"\n",
      "artifact_path = \"afc\"\n",
      "\n",
      "üìç –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –≤ S3:\n",
      "s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/739364c47b914c918bd68dae8fa3f46a/artifacts/afc/\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–¥–∞–Ω–∏–µ 2: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "bucket_name = os.getenv(\"S3_BUCKET_NAME\")  # –∏–º—è –±–∞–∫–µ—Ç–∞ S3\n",
    "experiment_id = afc_experiment_id  # ID —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "run_id = afc_run_id  # run_id —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –æ–±—ä–µ–∫—Ç afc\n",
    "artifact_path = afc_artifact_path  # artifact_path –æ–±—ä–µ–∫—Ç–∞ afc\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 2\")\n",
    "print(\"=\"*70)\n",
    "print(f'bucket_name = \"{bucket_name}\"')\n",
    "print(f'experiment_id = {experiment_id}')\n",
    "print(f'run_id = \"{run_id}\"')\n",
    "print(f'artifact_path = \"{artifact_path}\"')\n",
    "print(f'\\nüìç –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –≤ S3:')\n",
    "print(f's3://{bucket_name}/{experiment_id}/{run_id}/artifacts/{artifact_path}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9kmvo36cdrk",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 3\n",
    "–¢–µ–ø–µ—Ä—å –æ–±—É—á–∏—Ç–µ –≤–∞—à—É –º–æ–¥–µ–ª—å —Å —É—á—ë—Ç–æ–º –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –í –∫–æ–Ω—Ü–µ –µ—ë –Ω—É–∂–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å. –í –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∏–∂–µ –≤—Å—Ç–∞–≤—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç—Ç–æ–º.\n",
    "\n",
    "```python\n",
    "model_version_id = # –Ω–æ–º–µ—Ä –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "model_registred_name = \"\" # –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "run_id = \"\" # run_id —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "v5umco8fgtq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –ù–û–í–´–ú–ò –ü–†–ò–ó–ù–ê–ö–ê–ú–ò\n",
      "======================================================================\n",
      "\n",
      "üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:\n",
      "  X_train_features: (5634, 41)\n",
      "  X_test_features: (1409, 41)\n",
      "  y_train: (5634,)\n",
      "  y_test: (1409,)\n",
      "  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: [4432 1202]\n",
      "\n",
      "ü§ñ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier...\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!\n",
      "\n",
      "üìà –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ:\n",
      "  accuracy: 0.8811\n",
      "  precision: 0.8402\n",
      "  recall: 0.5466\n",
      "  f1: 0.6623\n",
      "\n",
      "üìà –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:\n",
      "  accuracy: 0.5451\n",
      "  precision: 0.5102\n",
      "  recall: 0.9715\n",
      "  f1: 0.6691\n",
      "  roc_auc: 0.7029\n",
      "\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –ù–û–í–´–ú–ò –ü–†–ò–ó–ù–ê–ö–ê–ú–ò\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "print(f\"\\nüìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"  X_train_features: {X_train_features.shape}\")\n",
    "print(f\"  X_test_features: {X_test_features.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(y_train)}\")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "print(f\"\\nü§ñ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier...\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_features, y_train)\n",
    "print(f\"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!\")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_train_pred = model.predict(X_train_features)\n",
    "y_test_pred = model.predict(X_test_features)\n",
    "y_test_proba = model.predict_proba(X_test_features)[:, 1]\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "train_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "    \"precision\": precision_score(y_train, y_train_pred),\n",
    "    \"recall\": recall_score(y_train, y_train_pred),\n",
    "    \"f1\": f1_score(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "test_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "    \"precision\": precision_score(y_test, y_test_pred),\n",
    "    \"recall\": recall_score(y_test, y_test_pred),\n",
    "    \"f1\": f1_score(y_test, y_test_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_test_proba)\n",
    "}\n",
    "\n",
    "print(f\"\\nüìà –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ:\")\n",
    "for metric_name, metric_value in train_metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:\")\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ot1htavz6mg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ò –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –í MLFLOW\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Run ID: 71f3c92a962f48f4903846391a0a3c54\n",
      "‚úÖ Artifact URI: s3://s3-student-mle-20250507-39f5f3ff21-freetrack/4/71f3c92a962f48f4903846391a0a3c54/artifacts\n",
      "\n",
      "üìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...\n",
      "‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ MLflow...\n",
      "  ‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: /var/folders/6g/s9qby9js2yd4gy8c0t6tftgh0000gp/T/tmpehn2yg6l/churn-classifier-autofeat/model.pkl\n",
      "\n",
      "üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MLflow...\n",
      "‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!\n",
      "üèÉ View run model_training_with_autofeat at: http://127.0.0.1:5001/#/experiments/4/runs/71f3c92a962f48f4903846391a0a3c54\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/4\n",
      "\n",
      "üîó View run: http://127.0.0.1:5001/#/experiments/4/runs/71f3c92a962f48f4903846391a0a3c54\n",
      "\n",
      "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 3 —Å–µ–∫—É–Ω–¥—ã...\n",
      "\n",
      "======================================================================\n",
      "–†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –í MODEL REGISTRY\n",
      "======================================================================\n",
      "\n",
      "üìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...\n",
      "  Model URI: runs:/71f3c92a962f48f4903846391a0a3c54/churn-classifier-autofeat\n",
      "  Model Name: churn-classifier-autofeat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'churn-classifier-autofeat'.\n",
      "2025/12/07 16:37:45 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: churn-classifier-autofeat, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!\n",
      "  Model Name: churn-classifier-autofeat\n",
      "  Version: 1\n",
      "  Run ID: 71f3c92a962f48f4903846391a0a3c54\n",
      "\n",
      "======================================================================\n",
      "üìù –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3:\n",
      "======================================================================\n",
      "model_version_id = 1\n",
      "model_registred_name = \"churn-classifier-autofeat\"\n",
      "run_id = \"71f3c92a962f48f4903846391a0a3c54\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'churn-classifier-autofeat'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import tempfile\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"–õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ò –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –í MLFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "REGISTRY_MODEL_NAME = \"churn-classifier-autofeat\"\n",
    "MODEL_RUN_NAME = \"model_training_with_autofeat\"\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π run –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "with mlflow.start_run(run_name=MODEL_RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    model_run_id = run.info.run_id\n",
    "    \n",
    "    print(f\"\\n‚úÖ Run ID: {model_run_id}\")\n",
    "    print(f\"‚úÖ Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    mlflow.log_param(\"min_samples_split\", 5)\n",
    "    mlflow.log_param(\"min_samples_leaf\", 2)\n",
    "    mlflow.log_param(\"n_features\", X_train_features.shape[1])\n",
    "    mlflow.log_param(\"with_autofeat\", True)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    print(\"\\nüìä –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...\")\n",
    "    for metric_name, metric_value in train_metrics.items():\n",
    "        mlflow.log_metric(f\"train_{metric_name}\", metric_value)\n",
    "    \n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "    \n",
    "    print(\"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ log_artifacts (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ afc)\n",
    "    print(\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ MLflow...\")\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # –°–æ–∑–¥–∞—ë–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "        model_artifact_path = REGISTRY_MODEL_NAME\n",
    "        model_dir = os.path.join(tmpdir, model_artifact_path)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å\n",
    "        model_pkl_path = os.path.join(model_dir, \"model.pkl\")\n",
    "        with open(model_pkl_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"  ‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_pkl_path}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º MLmodel —Ñ–∞–π–ª\n",
    "        mlmodel_content = f\"\"\"artifact_path: {model_artifact_path}\n",
    "flavors:\n",
    "  python_function:\n",
    "    env:\n",
    "      conda: conda.yaml\n",
    "      virtualenv: python_env.yaml\n",
    "    loader_module: mlflow.sklearn\n",
    "    model_path: model.pkl\n",
    "    predict_fn: predict\n",
    "    python_version: 3.12.7\n",
    "  sklearn:\n",
    "    code: null\n",
    "    pickled_model: model.pkl\n",
    "    serialization_format: cloudpickle\n",
    "    sklearn_version: 1.5.2\n",
    "mlflow_version: 2.18.0\n",
    "model_size_bytes: {os.path.getsize(model_pkl_path)}\n",
    "model_uuid: {model_run_id}\n",
    "run_id: {model_run_id}\n",
    "utc_time_created: '2025-12-07 16:30:00.000000'\n",
    "\"\"\"\n",
    "        with open(os.path.join(model_dir, \"MLmodel\"), 'w') as f:\n",
    "            f.write(mlmodel_content)\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º requirements.txt\n",
    "        with open(os.path.join(model_dir, \"requirements.txt\"), 'w') as f:\n",
    "            f.write(\"scikit-learn==1.5.2\\\\nautofeat\\\\npandas\\\\nnumpy\\\\n\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º conda.yaml\n",
    "        conda_yaml = \"\"\"channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.12.7\n",
    "- pip<=24.2\n",
    "- pip:\n",
    "  - mlflow==2.18.0\n",
    "  - cloudpickle==3.1.0\n",
    "  - scikit-learn==1.5.2\n",
    "  - autofeat\n",
    "name: mlflow-env\n",
    "\"\"\"\n",
    "        with open(os.path.join(model_dir, \"conda.yaml\"), 'w') as f:\n",
    "            f.write(conda_yaml)\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º python_env.yaml\n",
    "        python_env = \"\"\"python: 3.12.7\n",
    "build_dependencies:\n",
    "- pip==24.2\n",
    "- setuptools\n",
    "- wheel\n",
    "dependencies:\n",
    "- -r requirements.txt\n",
    "\"\"\"\n",
    "        with open(os.path.join(model_dir, \"python_env.yaml\"), 'w') as f:\n",
    "            f.write(python_env)\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "        print(f\"\\nüì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MLflow...\")\n",
    "        mlflow.log_artifacts(tmpdir)\n",
    "    \n",
    "    print(f\"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!\")\n",
    "\n",
    "print(f\"\\nüîó View run: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}/#/experiments/{experiment_id}/runs/{model_run_id}\")\n",
    "\n",
    "# –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏\n",
    "print(\"\\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 3 —Å–µ–∫—É–Ω–¥—ã...\")\n",
    "time.sleep(3)\n",
    "\n",
    "# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ Model Registry\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"–†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –í MODEL REGISTRY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_uri = f\"runs:/{model_run_id}/{REGISTRY_MODEL_NAME}\"\n",
    "\n",
    "print(f\"\\nüìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...\")\n",
    "print(f\"  Model URI: {model_uri}\")\n",
    "print(f\"  Model Name: {REGISTRY_MODEL_NAME}\")\n",
    "\n",
    "try:\n",
    "    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    model_version = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=REGISTRY_MODEL_NAME,\n",
    "        tags={\"features\": \"autofeat\", \"experiment\": EXPERIMENT_NAME}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!\")\n",
    "    print(f\"  Model Name: {model_version.name}\")\n",
    "    print(f\"  Version: {model_version.version}\")\n",
    "    print(f\"  Run ID: {model_version.run_id}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∑–∞–¥–∞–Ω–∏—è\n",
    "    registered_model_version_id = model_version.version\n",
    "    registered_model_name = model_version.name\n",
    "    registered_run_id = model_version.run_id\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìù –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"model_version_id = {registered_model_version_id}\")\n",
    "print(f'model_registred_name = \"{registered_model_name}\"')\n",
    "print(f'run_id = \"{registered_run_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "crw6vdzj6xe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3\n",
      "======================================================================\n",
      "model_version_id = 1\n",
      "model_registred_name = \"churn-classifier-autofeat\"\n",
      "run_id = \"71f3c92a962f48f4903846391a0a3c54\"\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–¥–∞–Ω–∏–µ 3: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "model_version_id = registered_model_version_id  # –Ω–æ–º–µ—Ä –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "model_registred_name = registered_model_name  # –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "run_id = registered_run_id  # run_id —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ –ó–ù–ê–ß–ï–ù–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ù–ò–Ø 3\")\n",
    "print(\"=\"*70)\n",
    "print(f\"model_version_id = {model_version_id}\")\n",
    "print(f'model_registred_name = \"{model_registred_name}\"')\n",
    "print(f'run_id = \"{run_id}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
