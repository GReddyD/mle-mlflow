{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48266e0d",
   "metadata": {},
   "source": [
    "# Работа с различными типами признаков\n",
    "В первом спринте вы уже проводили анализ вашего датасета. Тогда вы изучили типы данных, которые присутствовали в выборке, и проанализировали каждый тип признаков. Тот опыт был необходим — это основа работы с данными. Теперь, когда вы на этапе подготовки модели к продакшену, пора расширить ваши знания в нескольких областях.\n",
    "В реальной жизни данные зачастую разнообразны и неоднородны. Перед началом обучения модели нужно выполнить предварительную обработку (англ. preprocessing) — она касается различных типов признаков: числовых, текстовых, дат и других. В этом уроке мы расскажем о методах обработки.\n",
    "Один из ключевых этапов уже после предобработки данных — конструирование признаков (англ. feature engineering). Облегчат этот процесс несколько существующих и уже знакомых вам инструментов: Pipeline и ColumnTransformer из библиотеки scikit-learn. В ходе урока мы затронем их ещё раз. \n",
    "Для успешной предварительной обработки сначала нужно отделить данные разных типов друг от друга. Для этой задачи у датафрейма из библиотеки pandas есть метод select_dtypes, который позволяет включать (параметр include) или исключать (параметр exclude) определённые типы данных. Вот некоторые из типов данных:\n",
    "для выбора всех числовых типов используют np.number или 'number';\n",
    "для выбора чисел с плавающей запятой используют ‘float’ или, например, ‘float64’;\n",
    "для выбора строковых типов данных используют object dtype, однако помните, что это вернёт все столбцы с object dtype — даже категориальные признаки;\n",
    "Для выбора дат используют np.datetime64, 'datetime' или 'datetime64'.\n",
    "Полный список названий типов базируется на библиотеке NumPy, c их иерархией можно ознакомиться в документации на официальном сайте NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705b494",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "В коде ниже мы генерируем несколько колонок с данными и объединяем их в единый датафрейм, сохранённый в переменную df. Ваша задача — прописать информацию о типах данных, содержащихся в переменной df, а также создать переменные df_int, df_float, df_bool, df_object, df_date, куда сохранятся наборы данных, соответствующие этим типам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe8a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Типы данных в датафрейме:\n",
      "temperature_celsius           float64\n",
      "age_years                       int64\n",
      "timestamp_event        datetime64[ns]\n",
      "product_category               object\n",
      "is_purchased                     bool\n",
      "humidity_percentage           float64\n",
      "income_usd                      int64\n",
      "last_updated           datetime64[ns]\n",
      "product_name                   object\n",
      "is_subscribed                    bool\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "\n",
      "Колонки типа int:\n",
      "['age_years', 'income_usd']\n",
      "\n",
      "Количество колонок: 2\n",
      "\n",
      "Колонки типа float:\n",
      "['temperature_celsius', 'humidity_percentage']\n",
      "\n",
      "Количество колонок: 2\n",
      "\n",
      "Колонки типа bool:\n",
      "['is_purchased', 'is_subscribed']\n",
      "\n",
      "Количество колонок: 2\n",
      "\n",
      "Колонки типа object:\n",
      "['product_category', 'product_name']\n",
      "\n",
      "Количество колонок: 2\n",
      "\n",
      "Колонки типа datetime:\n",
      "['timestamp_event', 'last_updated']\n",
      "\n",
      "Количество колонок: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "\n",
    "# генерация данных для каждого столбца\n",
    "data = {\n",
    "    'temperature_celsius': np.random.uniform(20, 35, size=100),  # температура в градусах Цельсия (float)\n",
    "    'age_years': np.random.randint(18, 65, size=100),  # возраст в годах (int)\n",
    "    'timestamp_event': [pd.Timestamp('20230101') + timedelta(days=i) for i in range(100)],  # время события (datetime)\n",
    "    'product_category': np.random.choice(['electronics', 'clothing', 'food'], size=100),  # категория продукта (string)\n",
    "    'is_purchased': np.random.choice([True, False], size=100),  # булевое значение приобретения (bool)\n",
    "    'humidity_percentage': np.random.uniform(40, 80, size=100),  # влажность в процентах (float)\n",
    "    'income_usd': np.random.randint(20000, 100000, size=100),  # доход в долларах США (int)\n",
    "    'last_updated': [pd.Timestamp('20240101') + timedelta(days=i) for i in range(100)],  # последнее обновление (datetime)\n",
    "    'product_name': ['Product_' + str(i) for i in range(100)],  # название продукта (string)\n",
    "    'is_subscribed': np.random.choice([True, False], size=100)  # булевое значение подписки (bool)\n",
    "}\n",
    "\n",
    "# создание DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Информация о типах данных\n",
    "print(\"Типы данных в датафрейме:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Выбор данных по типам\n",
    "df_int = df.select_dtypes(include='int')\n",
    "df_float = df.select_dtypes(include='float')\n",
    "df_bool = df.select_dtypes(include='bool')\n",
    "df_object = df.select_dtypes(include='object')\n",
    "df_date = df.select_dtypes(include='datetime')\n",
    "\n",
    "# Проверка результатов\n",
    "print(\"Колонки типа int:\")\n",
    "print(df_int.columns.tolist())\n",
    "print(f\"\\nКоличество колонок: {len(df_int.columns)}\\n\")\n",
    "\n",
    "print(\"Колонки типа float:\")\n",
    "print(df_float.columns.tolist())\n",
    "print(f\"\\nКоличество колонок: {len(df_float.columns)}\\n\")\n",
    "\n",
    "print(\"Колонки типа bool:\")\n",
    "print(df_bool.columns.tolist())\n",
    "print(f\"\\nКоличество колонок: {len(df_bool.columns)}\\n\")\n",
    "\n",
    "print(\"Колонки типа object:\")\n",
    "print(df_object.columns.tolist())\n",
    "print(f\"\\nКоличество колонок: {len(df_object.columns)}\\n\")\n",
    "\n",
    "print(\"Колонки типа datetime:\")\n",
    "print(df_date.columns.tolist())\n",
    "print(f\"\\nКоличество колонок: {len(df_date.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ffdfc",
   "metadata": {},
   "source": [
    "Сейчас, когда вы научились отбирать нужные типы данных, рассмотрите способы их эффективной обработки. За это отвечает модуль preprocessing в библиотеке scikit-learn. Он предоставляет широкий спектр инструментов, которые помогут вам не только преобразовать данные, но и подготовить их к использованию в моделях машинного обучения.\n",
    "Для чего эти инструменты будут полезны:\n",
    "Для кодирования категориальных переменных в числовые — это позволит моделям работать с данными, которые содержат текстовую или категориальную информацию;\n",
    "Для нормализации данных — так улучшится их интерпретируемость для модели;\n",
    "Для заполнения пропущенных значений;\n",
    "Для масштабирования числовых признаков, чтобы модель справилась с данными в различных диапазонах.\n",
    "Ниже приведён полный список доступных объектов и методов предобработки данных в модуле preprocessing из библиотеки scikit-learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47786f1b",
   "metadata": {},
   "source": [
    "Подробнее про них вы можете прочитать в документации на официальном сайте sklearn.\n",
    "Каждый объект предобработки данных обладает набором методов, который делает его универсальным для работы с данными различных типов. Вот основные методы:\n",
    "fit — оценка параметров модели на основе данных X,\n",
    "transform — преобразование данных X,\n",
    "fit_transform — поочерёдное применение методов выше к данным X.\n",
    "Также есть несколько дополнительных: \n",
    "get_feature_names_out — получение имён выходных признаков после преобразования,\n",
    "get_params — получение параметров модели. Метод, который возвращает параметры объекта, установленные во время инициализации,\n",
    "inverse_transform — обратное преобразование данных X. Метод, который использует ранее рассчитанные параметры, чтобы вернуть данные к исходному масштабу,\n",
    "set_params — установка параметров модели. Этот метод позволяет задать параметры модели после её инициализации.\n",
    "Чтобы ознакомиться с ними подробнее, загляните на официальный сайт sklearn.\n",
    "Основные методы можно применить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "[ 2.,  0.,  0.],\n",
    "[ 0.,  1., -1.]])\n",
    "\n",
    "transformer = StandardScaler().fit(X_train) # оцениваем параметры модели\n",
    "transformer.mean_ # получаем средние значения для преобразования\n",
    "transformer.scale_ # получаем масштабы для преобразования\n",
    "\n",
    "X_scaled = transformer.transform(X_train) # применяем преобразование к данным\n",
    "X_scaled # получаем преобразованные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e344",
   "metadata": {},
   "source": [
    "Посмотрите на другие популярные преобразования:\n",
    "OneHotEncoder (унитарное кодирование)\n",
    "  Этот энкодер преобразует категориальные (дискретные) признаки в числовые, создавая бинарные столбцы для каждой категории. В качестве входных данных для этого преобразования должен выступать массив целых чисел или строк, чьи значения принимаются как категориальные признаки. Энкодер создаёт разреженную матрицу или массив (в зависимости от параметра sparse_output). Это кодирование необходимо для подачи категориальных данных во многие оценщики scikit-learn, особенно в линейные модели и SVM (метод опорных векторов) со стандартными ядрами.\n",
    "  Пример использования: если у вас есть признак «Тип автомобиля» с категориями «Седан», «Хэтчбек», «Универсал», то OneHotEncoder поможет преобразовать его в бинарные столбцы, чтобы использовать в моделях машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "data = np.array(['Универсал', 'Седан', 'Универсал', 'Хэтчбек']).reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(data).toarray()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67873d",
   "metadata": {},
   "source": [
    "\n",
    "SplineTransformer (преобразование сплайнов)\n",
    "  Этот энкодер создаёт новую матрицу признаков, состоящую из сплайнов порядка degree. Количество сгенерированных сплайнов равно n_splines=n_knots + degree - 1 для каждого признака, где\n",
    "n_knots определяет количество узлов (точек, в которых сопрягаются сплайны) для каждого признака. Он указывает, сколько понадобится точек, чтобы разбить признак на интервалы. В этих интервалах сплайны будут аппроксимировать данные.\n",
    "degree определяет порядок полинома, используемого для построения сплайнов. Это число указывает степень полинома, применяемого для каждого сплайна.\n",
    "Пример сплайна:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d081d",
   "metadata": {},
   "source": [
    "   Пример использования: в финансовом анализе для оценки временных рядов (например, прогнозирования курсов валют) — с помощью сплайнов можно генерировать гладкие кривые, чтобы проследить изменения данных во времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "import numpy as np\n",
    "    \n",
    "X = np.random.rand(10, 1)\n",
    "transformer = SplineTransformer(n_knots=3, degree=2)\n",
    "X_transformed = transformer.fit_transform(X)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9920042",
   "metadata": {},
   "source": [
    "QuantileTransformer (квантильное преобразование)\n",
    "  Этот метод преобразует признаки, чтобы они распределялись равномерно или нормально — так данные меньше подвергаются влиянию выбросов. Преобразование применяется к каждому признаку независимо. Идея метода такова: оценить функцию распределения признака, чтобы преобразовать исходные значения в равномерное распределение. \n",
    "  Пример использования: если у вас есть данные о доходах с широким диапазоном значений, квантильное преобразование сделает их более сопоставимыми и устойчивыми к выбросам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  from sklearn.preprocessing import QuantileTransformer\n",
    "  import numpy as np\n",
    "  \n",
    "  X = np.random.rand(10, 1)\n",
    "  transformer = QuantileTransformer()\n",
    "  X_transformed = transformer.fit_transform(X)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfab3b",
   "metadata": {},
   "source": [
    "KBinsDiscretizer (дискретизация признаков)\n",
    "  Этот энкодер разбивает непрерывные данные на интервалы.\n",
    "  Пример использования: если вам нужно проанализировать рынок потребления товаров в зависимости от возраста покупателей, то KBinsDiscretizer поможет с группировкой возрастных данных по группам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1999ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  from sklearn.preprocessing import KBinsDiscretizer\n",
    "  import numpy as np\n",
    "  \n",
    "  X = np.array([[2.3], [5.6], [7.8], [1.2]])\n",
    "  est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "  est.fit(X)\n",
    "  transformed = est.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd9eb1",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Примените преобразования к вашим данным:\n",
    "Binarizer — к колонке income_usd (в качестве границы возьмите средние значения). Результат сохраните в колонку income_usd_binarized.\n",
    "StandardScaler — к колонке age_years. Результат сохраните в колонку age_years_standarded.\n",
    "LabelEncoder — к колонке is_subscribed. Результат сохраните в колонку is_subscribed_encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0adc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler, LabelEncoder\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "\n",
    "# генерация данных для каждого столбца\n",
    "data = {\n",
    "    'temperature_celsius': np.random.uniform(20, 35, size=100),  # температура в градусах Цельсия (float)\n",
    "    'age_years': np.random.randint(18, 65, size=100),  # возраст в годах (int)\n",
    "    'timestamp_event': [pd.Timestamp('20230101') + timedelta(days=i) for i in range(100)],  # время события (datetime)\n",
    "    'product_category': np.random.choice(['electronics', 'clothing', 'food'], size=100),  # категория продукта (string)\n",
    "    'is_purchased': np.random.choice([True, False], size=100),  # булевое значение приобретения (bool)\n",
    "    'humidity_percentage': np.random.uniform(40, 80, size=100),  # влажность в процентах (float)\n",
    "    'income_usd': np.random.randint(20000, 100000, size=100),  # доход в долларах США (int)\n",
    "    'last_updated': [pd.Timestamp('20240101') + timedelta(days=i) for i in range(100)],  # последнее обновление (datetime)\n",
    "    'product_name': ['Product_' + str(i) for i in range(100)],  # название продукта (string)\n",
    "    'is_subscribed': np.random.choice([True, False], size=100)  # булевое значение подписки (bool)\n",
    "}\n",
    "\n",
    "# создание DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Применение Binarizer к income_usd с порогом = среднему значению\n",
    "threshold = df['income_usd'].mean()\n",
    "print(f\"Среднее значение income_usd (порог для бинаризации): {threshold:.2f}\")\n",
    "\n",
    "binarizer = Binarizer(threshold=threshold)\n",
    "df['income_usd_binarized'] = binarizer.fit_transform(df[['income_usd']])\n",
    "\n",
    "# 2. Применение StandardScaler к age_years\n",
    "scaler = StandardScaler()\n",
    "df['age_years_standarded'] = scaler.fit_transform(df[['age_years']])\n",
    "\n",
    "# 3. Применение LabelEncoder к is_subscribed\n",
    "encoder = LabelEncoder()\n",
    "df['is_subscribed_encoded'] = encoder.fit_transform(df['is_subscribed'])\n",
    "\n",
    "# Проверка результатов\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Результаты преобразований:\\n\")\n",
    "\n",
    "print(\"1. Binarizer для income_usd:\")\n",
    "print(df[['income_usd', 'income_usd_binarized']].head(10))\n",
    "print(f\"\\nРаспределение бинаризованных значений:\")\n",
    "print(df['income_usd_binarized'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. StandardScaler для age_years:\")\n",
    "print(df[['age_years', 'age_years_standarded']].head(10))\n",
    "print(f\"\\nСтатистика стандартизированных значений:\")\n",
    "print(f\"Среднее: {df['age_years_standarded'].mean():.10f}\")\n",
    "print(f\"Стандартное отклонение: {df['age_years_standarded'].std():.10f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. LabelEncoder для is_subscribed:\")\n",
    "print(df[['is_subscribed', 'is_subscribed_encoded']].head(10))\n",
    "print(f\"\\nСоответствие меток:\")\n",
    "print(f\"False -> {encoder.transform([False])[0]}\")\n",
    "print(f\"True -> {encoder.transform([True])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fddca4",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Примените преобразования к вашим данным, используя объект ColumnTransformer внутри Pipeline. Используйте преобразования из предыдущего задания:\n",
    "Binarizer — к колонке income_usd (в качестве границы возьмите средние значения),\n",
    "StandardScaler — к колонке age_years,\n",
    "OneHotEncoder — к колонке is_subscribed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "\n",
    "# генерация данных для каждого столбца\n",
    "data = {\n",
    "    'temperature_celsius': np.random.uniform(20, 35, size=100),  # температура в градусах Цельсия (float)\n",
    "    'age_years': np.random.randint(18, 65, size=100),  # возраст в годах (int)\n",
    "    'timestamp_event': [pd.Timestamp('20230101') + timedelta(days=i) for i in range(100)],  # время события (datetime)\n",
    "    'product_category': np.random.choice(['electronics', 'clothing', 'food'], size=100),  # категория продукта (string)\n",
    "    'is_purchased': np.random.choice([True, False], size=100),  # булевое значение приобретения (bool)\n",
    "    'humidity_percentage': np.random.uniform(40, 80, size=100),  # влажность в процентах (float)\n",
    "    'income_usd': np.random.randint(20000, 100000, size=100),  # доход в долларах США (int)\n",
    "    'last_updated': [pd.Timestamp('20240101') + timedelta(days=i) for i in range(100)],  # последнее обновление (datetime)\n",
    "    'product_name': ['Product_' + str(i) for i in range(100)],  # название продукта (string)\n",
    "    'is_subscribed': np.random.choice([True, False], size=100)  # булевое значение подписки (bool)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вычисляем среднее значение для Binarizer\n",
    "threshold = df['income_usd'].mean()\n",
    "print(f\"Среднее значение income_usd (порог для бинаризации): {threshold:.2f}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# создание ColumnTransformer с преобразованиями для различных колонок\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binarizer', Binarizer(threshold=threshold), ['income_usd']),\n",
    "        ('scaler', StandardScaler(), ['age_years']),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False, drop=None), ['is_subscribed'])\n",
    "    ],\n",
    "    remainder='drop'  # остальные колонки НЕ включаем (избегаем проблем с типами)\n",
    ")\n",
    "\n",
    "# создание Pipeline с преобразованиями\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# применение преобразований\n",
    "transformed_data = pipe.fit_transform(df)\n",
    "\n",
    "print(\"Результаты преобразований:\")\n",
    "print(f\"Форма преобразованных данных: {transformed_data.shape}\")\n",
    "print(f\"Тип данных: {type(transformed_data)}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Получаем имена признаков\n",
    "feature_names = []\n",
    "# Binarizer - 1 признак\n",
    "feature_names.append('income_usd_binarized')\n",
    "# StandardScaler - 1 признак\n",
    "feature_names.append('age_years_scaled')\n",
    "# OneHotEncoder - получаем имена автоматически\n",
    "ohe_features = pipe.named_steps['preprocessor'].named_transformers_['onehot'].get_feature_names_out(['is_subscribed'])\n",
    "feature_names.extend(ohe_features)\n",
    "\n",
    "print(f\"Имена признаков после преобразования: {feature_names}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Создаём DataFrame с результатами\n",
    "df_transformed = pd.DataFrame(\n",
    "    transformed_data, \n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "print(\"Первые 10 строк преобразованных данных:\")\n",
    "print(df_transformed.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nСравнение исходных и преобразованных данных:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'income_usd': df['income_usd'].head(10).values,\n",
    "    'income_binarized': df_transformed['income_usd_binarized'].head(10).values,\n",
    "    'age_years': df['age_years'].head(10).values,\n",
    "    'age_scaled': df_transformed['age_years_scaled'].head(10).values.round(3),\n",
    "    'is_subscribed': df['is_subscribed'].head(10).values,\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nСтатистика преобразованных признаков:\")\n",
    "print(f\"\\nBinarizer (income_usd):\")\n",
    "print(f\"  Значений 0 (ниже среднего): {(df_transformed['income_usd_binarized'] == 0).sum()}\")\n",
    "print(f\"  Значений 1 (выше среднего): {(df_transformed['income_usd_binarized'] == 1).sum()}\")\n",
    "\n",
    "print(f\"\\nStandardScaler (age_years):\")\n",
    "print(f\"  Среднее: {df_transformed['age_years_scaled'].mean():.10f}\")\n",
    "print(f\"  Std: {df_transformed['age_years_scaled'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nOneHotEncoder (is_subscribed):\")\n",
    "print(f\"  False: {df_transformed['is_subscribed_False'].sum():.0f}\")\n",
    "print(f\"  True: {df_transformed['is_subscribed_True'].sum():.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nПолная структура преобразованных данных:\")\n",
    "print(df_transformed.info())\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(df_transformed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7961a90",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Вы работаете с данными о ежедневных температурах в градусах Цельсия за год в определённом регионе. Ваша задача — предобработать временные данные, чтобы затем их можно было использовать в модели машинного обучения. Выполните следующие шаги:\n",
    "извлеките признаки из даты,\n",
    "рассчитайте среднюю температуру за последние семь дней (скользящее окно) и накопительную сумму за весь период,\n",
    "добавьте признаки, отражающие общий тренд в данных (сумма температур за каждый месяц) и периодичность событий (средняя температура по месяцам)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# генерация случайных данных о температурах за год\n",
    "np.random.seed(42)\n",
    "np.random.default_rng(42)\n",
    "start_date = pd.Timestamp('2023-01-01')\n",
    "end_date = pd.Timestamp('2023-12-31')\n",
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "temperatures = np.random.uniform(low=-10.0, high=30.0, size=len(dates))\n",
    "temperature_data = pd.DataFrame({'Date': dates, 'Temperature_Celsius': temperatures})\n",
    "\n",
    "# ваш код для предобработки временных признаков #\n",
    "\n",
    "# 1. Извлечение признаков из даты\n",
    "temperature_data['Month'] = temperature_data['Date'].dt.month\n",
    "temperature_data['Weekday'] = temperature_data['Date'].dt.weekday\n",
    "temperature_data['Hour'] = temperature_data['Date'].dt.hour\n",
    "\n",
    "# 2. Скользящие окна и накопительные статистики\n",
    "temperature_data['Cumulative_Sum'] = temperature_data['Temperature_Celsius'].cumsum()\n",
    "\n",
    "# 3. Периодичность и тренды\n",
    "temperature_data['Monthly_Sum'] = temperature_data.groupby('Month')['Temperature_Celsius'].transform('sum')\n",
    "temperature_data['Monthly_Mean'] = temperature_data.groupby('Month')['Temperature_Celsius'].transform('mean')\n",
    "\n",
    "# вывод обработанных данных\n",
    "print(temperature_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
