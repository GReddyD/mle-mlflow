{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f453c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¥–µ–ª–∞–µ–º import –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –Ω–∞—à–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
    "# —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ç–∞–∫–æ–µ –∂–µ, –∫–∞–∫ –∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–∏—Å–∞\n",
    "mlflow.set_tracking_uri('file:./mlflow_experiments_store')\n",
    "\n",
    "# –ø–æ–ª—É—á–∞–µ–º id —ç–∫—Å–µ—Ä–∏–º–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "# —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "# –∑–∞–ª–æ–≥–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç\n",
    "with mlflow.start_run(run_name='Default', experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_metric(\"test_metric\", 0)\n",
    "    mlflow.log_artifact(\"../test_artifact.txt\", \"test_artifact\")  # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø—É—Ç—å\n",
    "\n",
    "print(f\"Run id –∑–∞–ø—É—Å–∫–∞: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0262d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_metric\n"
     ]
    }
   ],
   "source": [
    "!ls mlflow_experiments_store/0/{run_id}/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391ca5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_artifact\n"
     ]
    }
   ],
   "source": [
    "!cat mlflow_experiments_store/0/{run_id}/artifacts/test_artifact/test_artifact.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('http://0.0.0.0:5001')  # –∏–∑–º–µ–Ω–µ–Ω–æ —Å 5000 –Ω–∞ 5001\n",
    "\n",
    "# –ø–æ–ª—É—á–∞–µ–º id —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "# —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=\"Default\", experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(\"test_metric_sqlite\", 0)\n",
    "    mlflow.log_artifact(\"../test_artifact.txt\", \"test_artifact\")  # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø—É—Ç—å\n",
    "\n",
    "# –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ, –∞ —Ç–∞–∫–∂–µ —Å–æ–∑–¥–∞–ª–∞—Å—å –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö SQLite\n",
    "assert os.path.exists(\"../mlflow_experiments_store_sqlite\")  # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø—É—Ç—å\n",
    "assert os.path.exists(\"../mydb.sqlite\")  # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ø—É—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d432a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Experiment(name=test_connection_experiment_ALEKSANDR) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"experiments_name_key\"\nDETAIL:  Key (name)=(test_connection_experiment_ALEKSANDR) already exists.\n\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (%(name)s, %(artifact_location)s, %(lifecycle_stage)s, %(creation_time)s, %(last_update_time)s) RETURNING experiments.experiment_id]\n[parameters: {'name': 'test_connection_experiment_ALEKSANDR', 'artifact_location': '', 'lifecycle_stage': 'active', 'creation_time': 1763897308267, 'last_update_time': 1763897308267}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRACKING_SERVER_HOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRACKING_SERVER_PORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# —Å–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –Ω–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mcreate_experiment(EXPERIMENT_NAME)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39mRUN_NAME, experiment_id\u001b[38;5;241m=\u001b[39mexperiment_id) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m     41\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/tracking/fluent.py:2114\u001b[0m, in \u001b[0;36mcreate_experiment\u001b[0;34m(name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   2067\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   2068\u001b[0m     artifact_location: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2069\u001b[0m     tags: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2070\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;124;03m    Create an experiment.\u001b[39;00m\n\u001b[1;32m   2073\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;124;03m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[1;32m   2113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MlflowClient()\u001b[38;5;241m.\u001b[39mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/tracking/client.py:1852\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   1800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1802\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1803\u001b[0m     artifact_location: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1804\u001b[0m     tags: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1805\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m \n\u001b[1;32m   1808\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \n\u001b[1;32m   1851\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client\u001b[38;5;241m.\u001b[39mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/telemetry/track.py:30\u001b[0m, in \u001b[0;36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# noqa: RET504\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:298\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_experiment(\n\u001b[1;32m    299\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    300\u001b[0m     artifact_location\u001b[38;5;241m=\u001b[39martifact_location,\n\u001b[1;32m    301\u001b[0m     tags\u001b[38;5;241m=\u001b[39m[ExperimentTag(key, value) \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mitems()] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    302\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:254\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    250\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    251\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m    252\u001b[0m     CreateExperiment(name\u001b[38;5;241m=\u001b[39mname, artifact_location\u001b[38;5;241m=\u001b[39martifact_location, tags\u001b[38;5;241m=\u001b[39mtag_protos)\n\u001b[1;32m    253\u001b[0m )\n\u001b[0;32m--> 254\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_endpoint(CreateExperiment, req_body)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mexperiment_id\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:203\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001b[0m\n\u001b[1;32m    201\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_METHOD_TO_INFO[api]\n\u001b[1;32m    202\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m response_proto \u001b[38;5;129;01mor\u001b[39;00m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_endpoint(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_host_creds(),\n\u001b[1;32m    205\u001b[0m     endpoint,\n\u001b[1;32m    206\u001b[0m     method,\n\u001b[1;32m    207\u001b[0m     json_body,\n\u001b[1;32m    208\u001b[0m     response_proto,\n\u001b[1;32m    209\u001b[0m     retry_timeout_seconds\u001b[38;5;241m=\u001b[39mretry_timeout_seconds,\n\u001b[1;32m    210\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:596\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    593\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    594\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 596\u001b[0m response \u001b[38;5;241m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    597\u001b[0m response_to_parse \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:315\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 315\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Experiment(name=test_connection_experiment_ALEKSANDR) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"experiments_name_key\"\nDETAIL:  Key (name)=(test_connection_experiment_ALEKSANDR) already exists.\n\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (%(name)s, %(artifact_location)s, %(lifecycle_stage)s, %(creation_time)s, %(last_update_time)s) RETURNING experiments.experiment_id]\n[parameters: {'name': 'test_connection_experiment_ALEKSANDR', 'artifact_location': '', 'lifecycle_stage': 'active', 'creation_time': 1763897308267, 'last_update_time': 1763897308267}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ credentials, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MLflow\n",
    "# –≤–∞–∂–Ω–æ, —á—Ç–æ credentials –º—ã –ø–µ—Ä–µ–¥–∞—ë–º –¥–ª—è —Å–µ–±—è –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π Tracking Service\n",
    "# —É –≤–∞—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Å—Ç—É–ø –∫ –±–∞–∫–µ—Ç—É, –≤ –∫–æ—Ç–æ—Ä—ã–π –≤—ã –±—É–¥–µ—Ç–µ —Å–∫–ª–∞–¥—ã–≤–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint –±–∞–∫–µ—Ç–∞ –æ—Ç YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\") # –ø–æ–ª—É—á–∞–µ–º id –∫–ª—é—á–∞ –±–∞–∫–µ—Ç–∞, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –ø–æ–¥–∫–ª—é—á—ë–Ω MLFlow, –∏–∑ .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\") # –ø–æ–ª—É—á–∞–µ–º –∫–ª—é—á –±–∞–∫–µ—Ç–∞, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –ø–æ–¥–∫–ª—é—á—ë–Ω MLFlow, –∏–∑ .env\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n",
    "assert os.getenv(\"S3_ACCESS_KEY\") is not None, \"S3_ACCESS_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env\"\n",
    "assert os.getenv(\"S3_SECRET_KEY\") is not None, \"S3_SECRET_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env\"\n",
    "\n",
    "# –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
    "# –ø–æ–¥–Ω–∏–º–∞–µ–º MLflow –ª–æ–∫–∞–ª—å–Ω–æ\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5001  # –∏–∑–º–µ–Ω–µ–Ω–æ —Å 5000 –Ω–∞ 5001\n",
    "\n",
    "YOUR_NAME = \"ALEKSANDR\" # –≤–≤–µ–¥–∏—Ç–µ —Å–≤–æ—ë –∏–º—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "assert YOUR_NAME, \"ALEKSANDR\"\n",
    "\n",
    "# –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏ –∑–∞–ø—É—Å–∫–∞ (run) –≤–Ω—É—Ç—Ä–∏ –Ω–µ–≥–æ\n",
    "EXPERIMENT_NAME = f\"test_connection_experiment_{YOUR_NAME}\"\n",
    "RUN_NAME = \"test_connection_run\"\n",
    "\n",
    "# —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "METRIC_NAME = \"test_metric\"\n",
    "METRIC_VALUE = 0\n",
    "\n",
    "# —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º host, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –Ω–∞—à–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# —Å–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –Ω–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(METRIC_NAME, METRIC_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97fbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞\n",
    "load_dotenv('../.env')\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"), \n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "assert all([var_value is not None and var_value != \"\" for var_value in list(postgres_credentials.values())]), \"–ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã\"\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# –æ–ø—Ä–µ–¥–µ–ª–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã, –≤ –∫–æ—Ç–æ—Ä–æ–π —Ö—Ä–∞–Ω—è—Ç—Å—è –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ.\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "# —ç—Ç–∞ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö \n",
    "# –æ–ø–µ—Ä–∞—Ç–æ—Ä with –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –±—É–¥–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã—Ç–æ –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π \n",
    "# –∑–∞–∫—Ä—ã—Ç–æ –æ–Ω–æ –±—É–¥–µ—Ç –¥–∞–∂–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏, —á—Ç–æ–±—ã –Ω–µ –¥–æ–ø—É—Å—Ç–∏—Ç—å \"—É—Ç–µ—á–∫—É –ø–∞–º—è—Ç–∏\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# —Å–æ–∑–¥–∞—ë—Ç –æ–±—ä–µ–∫—Ç –∫—É—Ä—Å–æ—Ä–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "# —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ execute() –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è SQL-–∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # –∏–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ –∫—É—Ä—Å–æ—Ä–∞\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# —Å–æ–∑–¥–∞—ë—Ç –æ–±—ä–µ–∫—Ç DataFrame –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∏–º—ë–Ω —Å—Ç–æ–ª–±—Ü–æ–≤. \n",
    "# —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ Python, –∏—Å–ø–æ–ª—å–∑—É—è –±–∏–±–ª–∏–æ—Ç–µ–∫—É Pandas.\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63137f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –≤–∞—à–µ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –∑–∞–ø–∏—à–∏—Ç–µ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª\n",
    "with open(\"columns.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "    fio.write(\",\".join(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d62d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_columns = [\n",
    "    \"type\", \"paperless_billing\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "    \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\",\n",
    "    \"multiple_lines\", \"target\"\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for col in counts_columns:\n",
    "    column_stat = df[col].value_counts().to_dict()\n",
    "    column_stat = {f\"{col}_{key}\": int(value) for key, value in column_stat.items()}\n",
    "    stats.update(column_stat)\n",
    "\n",
    "stats[\"data_length\"] = int(df.shape[0])\n",
    "stats[\"monthly_charges_min\"] = float(df[\"monthly_charges\"].min())\n",
    "stats[\"monthly_charges_max\"] = float(df[\"monthly_charges\"].max())\n",
    "stats[\"monthly_charges_mean\"] = float(df[\"monthly_charges\"].mean())\n",
    "stats[\"monthly_charges_median\"] = float(df[\"monthly_charges\"].median())\n",
    "stats[\"total_charges_min\"] = float(df[\"total_charges\"].min())\n",
    "stats[\"total_charges_max\"] = float(df[\"total_charges\"].max())\n",
    "stats[\"total_charges_mean\"] = float(df[\"total_charges\"].mean())\n",
    "stats[\"total_charges_median\"] = float(df[\"total_charges\"].median())\n",
    "stats[\"unique_customers_number\"] = int(df[\"customer_id\"].nunique())\n",
    "stats[\"end_date_nan\"] = int(df[\"end_date\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e469607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ccf9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 14:28:53 INFO mlflow.tracking.fluent: Experiment with name 'churn_fio' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run data_check at: http://127.0.0.1:5001/#/experiments/3/runs/dea57f0d566b456bbd10e9597866f69a\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# –∑–∞–¥–∞—ë–º –Ω–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏ –∏–º—è –∑–∞–ø—É—Å–∫–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ MLflow\n",
    "EXPERIMENT_NAME = \"churn_fio\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "# —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç (—Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    # –ø–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # –ª–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "    mlflow.log_metrics(stats)\n",
    "    \n",
    "    # –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "    mlflow.log_artifact(\"columns.txt\", artifact_path=\"dataframe\")\n",
    "    mlflow.log_artifact(\"users_churn.csv\", artifact_path=\"dataframe\")\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–ø—É—Å–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –ø–æ –µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "# –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç–∞—Ç—É—Å –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏–∑–º–µ–Ω—ë–Ω –Ω–∞ 'FINISHED'\n",
    "assert run.info.status == \"FINISHED\"\n",
    "\n",
    "# —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã\n",
    "os.remove(\"columns.txt\")\n",
    "os.remove(\"users_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b538ac",
   "metadata": {},
   "source": [
    "## –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11701100",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–æ, –ø–æ–º–∏–º–æ —Å–∞–º–æ–π –º–æ–¥–µ–ª–∏, –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –∏ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏. –î–ª—è —ç—Ç–æ–≥–æ –æ—Ü–µ–Ω–∏–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º —ç—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π prediction, –∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ y_test.\n",
    "–ù–∞—á–Ω—ë–º —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫, –∏—Å–ø–æ–ª—å–∑—É—è –º–æ–¥—É–ª—å sklearn.metrics. –û—Ü–µ–Ω–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏:\n",
    "ROC-AUC,\n",
    "F1-–º–µ—Ä–∞,\n",
    "—Ç–æ—á–Ω–æ—Å—Ç—å ‚Äî precision,\n",
    "–ø–æ–ª–Ω–æ—Ç–∞ recall,\n",
    "–º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ ‚Äî confusion_matrix,\n",
    "logloss, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ç–µ—Ä–∏.\n",
    "–ó–Ω–∞—á–µ–Ω–∏—è —ç—Ç–∏—Ö –º–µ—Ç—Ä–∏–∫ –∑–∞–ø–∏—à–∏—Ç–µ –≤ —Å–ª–æ–≤–∞—Ä—å metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "597ede5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# –ø–æ—Å—á–∏—Ç–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –º–æ–¥—É–ª—è sklearn.metrics\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# err_1 ‚Äî –æ—à–∏–±–∫–∞ –ø–µ—Ä–≤–æ–≥–æ —Ä–æ–¥–∞ (False Positive)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# err_2 ‚Äî –æ—à–∏–±–∫–∞ –≤—Ç–æ—Ä–æ–≥–æ —Ä–æ–¥–∞ (False Negative)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m _, err1, _, err2 \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43my_test\u001b[49m, prediction, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     17\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, probas)\n\u001b[1;32m     18\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, prediction)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "# –∑–∞–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏\n",
    "metrics = {}\n",
    "\n",
    "# –ø–æ—Å—á–∏—Ç–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –º–æ–¥—É–ª—è sklearn.metrics\n",
    "# err_1 ‚Äî –æ—à–∏–±–∫–∞ –ø–µ—Ä–≤–æ–≥–æ —Ä–æ–¥–∞ (False Positive)\n",
    "# err_2 ‚Äî –æ—à–∏–±–∫–∞ –≤—Ç–æ—Ä–æ–≥–æ —Ä–æ–¥–∞ (False Negative)\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# –∑–∞–ø–∏—à–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172ae71",
   "metadata": {},
   "source": [
    "–†–∞–∑–≤–µ—Ä–Ω–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∑–∞–ø—É—Å–∫–∞ MLflow —Å —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –ø—Ä–æ –º–æ–¥—É–ª—å Model Registry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export MLFLOW_S3_ENDPOINT_URL=https://storage.yandexcloud.net\n",
    "export AWS_ACCESS_KEY_ID=$S3_ACCESS_KEY\n",
    "export AWS_SECRET_ACCESS_KEY=$S3_SECRET_KEY\n",
    "\n",
    "mlflow server \\\n",
    "    --backend-store-uri postgresql://mle_20250507_39f5f3ff21_freetrack:76bc4e5fcfcd46cd8da35b17e6d24263@rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net:6432/playground_mle_20250507_39f5f3ff21 \\\n",
    "    --registry-store-uri postgresql://mle_20250507_39f5f3ff21_freetrack:76bc4e5fcfcd46cd8da35b17e6d24263@rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net:6432/playground_mle_20250507_39f5f3ff21 \\\n",
    "    --default-artifact-root s3://s3-student-mle-20250507-39f5f3ff21-freetrack \\\n",
    "    --no-serve-artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca79b2",
   "metadata": {},
   "source": [
    "–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –≤–∞—à—É –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –≤ —Ä–µ–µ—Å—Ç—Ä–µ –º–æ–¥–µ–ª–µ–π —Å –ø–æ–ª—É—á–µ–Ω–Ω—ã–º —Å–ª–æ–≤–∞—Ä—ë–º –º–µ—Ç—Ä–∏–∫.\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç EXPERIMENT_NAME –∏ –Ω–æ–≤—ã–π –∑–∞–ø—É—Å–∫ RUN_NAME.\n",
    "–ò–º—è –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é REGISTRY_MODEL_NAME.\n",
    "–û–∫—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ –≤ —Ñ–∞–π–ª–µ requirements.txt.\n",
    "–°—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ —Å–∏–≥–Ω–∞—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –∏–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.\n",
    "–î–æ–±–∞–≤—å—Ç–µ –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä—É—é —Å—á–∏—Ç–∞–µ—Ç–µ –≤–∞–∂–Ω–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0406887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞\n",
    "load_dotenv('../.env')\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_prediction_stepanov\"  # –≤–∞—à–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "RUN_NAME = \"model_0_registry\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_nikolaistepanov\"\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow tracking –∏ registry URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")  # –∏–∑–º–µ–Ω–µ–Ω–æ —Å 5000 –Ω–∞ 5001\n",
    "mlflow.set_registry_uri(\"http://127.0.0.1:5001\")  # –∏–∑–º–µ–Ω–µ–Ω–æ —Å 5000 –Ω–∞ 5001\n",
    "\n",
    "\n",
    "pip_requirements = '../requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        pip_requirements=pip_requirements,\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        metadata=metadata,\n",
    "        await_registration_for=60\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eeba2",
   "metadata": {},
   "source": [
    "–î–æ—Å—Ç–∞–Ω—å—Ç–µ –º–æ–¥–µ–ª—å –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞ –∏ —Å –µ—ë –ø–æ–º–æ—â—å—é —Å–¥–µ–ª–∞–π—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730f4f9",
   "metadata": {},
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\n",
    "model_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "assert model_predictions.dtype == int\n",
    "\n",
    "print(model_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112799b",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4253f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "EXPERIMENT_NAME = \"my_own_experiment\"\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment is None:\n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "print(f\"Experiment ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "experiments = mlflow.search_experiments()\n",
    "\n",
    "print(\"–î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º runs:\")\n",
    "print(\"=\" * 60)\n",
    "for exp in experiments:\n",
    "    runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
    "    print(f\"Name: {exp.name}\")\n",
    "    print(f\"ID: {exp.experiment_id}\")\n",
    "    print(f\"Runs count: {len(runs)}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ MLflow\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"–ü–†–û–í–ï–†–ö–ê –ó–ê–†–ï–ì–ò–°–¢–†–ò–†–û–í–ê–ù–ù–´–• –ú–û–î–ï–õ–ï–ô\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "    registered_models = client.search_registered_models()\n",
    "\n",
    "    if not registered_models:\n",
    "        print(\"\\n–ú–æ–¥–µ–ª–µ–π –≤ —Ä–µ–µ—Å—Ç—Ä–µ –ù–ï –ù–ê–ô–î–ï–ù–û\")\n",
    "        print(\"\\n–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π.\")\n",
    "        print(\"–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python register_models.py\")\n",
    "    else:\n",
    "        print(f\"\\n–ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(registered_models)}\")\n",
    "        print(\"\\n–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:\")\n",
    "\n",
    "        for rm in registered_models:\n",
    "            print(f\"\\n  –ú–æ–¥–µ–ª—å: {rm.name}\")\n",
    "            print(f\"  –û–ø–∏—Å–∞–Ω–∏–µ: {rm.description}\")\n",
    "\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "            versions = client.search_model_versions(f\"name='{rm.name}'\")\n",
    "            print(f\"  –í–µ—Ä—Å–∏–π: {len(versions)}\")\n",
    "\n",
    "            for version in versions:\n",
    "                print(f\"\\n    –í–µ—Ä—Å–∏—è {version.version}:\")\n",
    "                print(f\"      Stage: {version.current_stage}\")\n",
    "                print(f\"      Run ID: {version.run_id}\")\n",
    "                print(f\"      –û–ø–∏—Å–∞–Ω–∏–µ: {version.description}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n–û–®–ò–ë–ö–ê: {e}\")\n",
    "    print(\"\\n–í–æ–∑–º–æ–∂–Ω–æ MLflow —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω.\")\n",
    "    print(\"–ó–∞–ø—É—Å—Ç–∏—Ç–µ: ./run_mlflow_server.sh\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d963b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–µ–π –≤ MLflow Model Registry\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"–î–ï–¢–ê–õ–¨–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –í–ï–†–°–ò–ô –ú–û–î–ï–õ–ï–ô\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "REGISTRY_MODEL_NAME = \"churn_model_production\"\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "    versions = client.search_model_versions(f\"name='{REGISTRY_MODEL_NAME}'\")\n",
    "\n",
    "    if not versions:\n",
    "        print(f\"\\n–ú–æ–¥–µ–ª—å '{REGISTRY_MODEL_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–µ—Å—Ç—Ä–µ\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"\\n–ú–æ–¥–µ–ª—å: {REGISTRY_MODEL_NAME}\")\n",
    "    print(f\"–í—Å–µ–≥–æ –≤–µ—Ä—Å–∏–π: {len(versions)}\")\n",
    "\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º –≤–µ—Ä—Å–∏—è–º\n",
    "    version_data = []\n",
    "\n",
    "    for version in sorted(versions, key=lambda x: int(x.version)):\n",
    "        run = client.get_run(version.run_id)\n",
    "\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        metrics = run.data.metrics\n",
    "        params = run.data.params\n",
    "\n",
    "        version_info = {\n",
    "            '–í–µ—Ä—Å–∏—è': version.version,\n",
    "            'Stage': version.current_stage if version.current_stage else 'None',\n",
    "            'Run ID': version.run_id[:8] + '...',\n",
    "            '–û–ø–∏—Å–∞–Ω–∏–µ': version.description[:50] + '...' if version.description and len(version.description) > 50 else version.description or '-',\n",
    "\n",
    "            # –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "            'ROC-AUC': metrics.get('roc_auc', metrics.get('auc', 0)),\n",
    "            'Accuracy': metrics.get('accuracy', 0),\n",
    "            'F1-Score': metrics.get('f1_score', metrics.get('f1', 0)),\n",
    "            'Precision': metrics.get('precision', 0),\n",
    "            'Recall': metrics.get('recall', 0),\n",
    "            'Log Loss': metrics.get('log_loss', metrics.get('logloss', 0)),\n",
    "\n",
    "            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "            'FPR': metrics.get('false_positive_rate', 0),\n",
    "            'FNR': metrics.get('false_negative_rate', 0),\n",
    "            'Specificity': metrics.get('specificity', 0),\n",
    "\n",
    "            # Confusion Matrix\n",
    "            'TP': int(metrics.get('true_positives', 0)),\n",
    "            'TN': int(metrics.get('true_negatives', 0)),\n",
    "            'FP': int(metrics.get('false_positives', 0)),\n",
    "            'FN': int(metrics.get('false_negatives', 0)),\n",
    "\n",
    "            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "            'Iterations': params.get('iterations', '-'),\n",
    "            'Depth': params.get('depth', '-'),\n",
    "            'LR': params.get('learning_rate', '-'),\n",
    "        }\n",
    "\n",
    "        version_data.append(version_info)\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    df = pd.DataFrame(version_data)\n",
    "\n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"–û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò\")\n",
    "    print(\"=\" * 100)\n",
    "    print(df[['–í–µ—Ä—Å–∏—è', 'Stage', 'ROC-AUC', 'Accuracy', 'F1-Score', 'Precision', 'Recall']].to_string(index=False))\n",
    "\n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò\")\n",
    "    print(\"=\" * 100)\n",
    "    print(df[['–í–µ—Ä—Å–∏—è', 'Stage', 'Log Loss', 'FPR', 'FNR', 'Specificity']].to_string(index=False))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"CONFUSION MATRIX\")\n",
    "    print(\"=\" * 100)\n",
    "    print(df[['–í–µ—Ä—Å–∏—è', 'Stage', 'TP', 'TN', 'FP', 'FN']].to_string(index=False))\n",
    "\n",
    "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"–ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ï–ô\")\n",
    "    print(\"=\" * 100)\n",
    "    print(df[['–í–µ—Ä—Å–∏—è', 'Stage', 'Iterations', 'Depth', 'LR']].to_string(index=False))\n",
    "\n",
    "    # –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ —Ä–∞–∑–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"–õ–£–ß–®–ò–ï –í–ï–†–°–ò–ò –ü–û –ú–ï–¢–†–ò–ö–ê–ú\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    best_metrics = {\n",
    "        'ROC-AUC': df.loc[df['ROC-AUC'].idxmax()],\n",
    "        'F1-Score': df.loc[df['F1-Score'].idxmax()],\n",
    "        'Recall': df.loc[df['Recall'].idxmax()],\n",
    "        'Precision': df.loc[df['Precision'].idxmax()],\n",
    "    }\n",
    "\n",
    "    for metric_name, best_row in best_metrics.items():\n",
    "        print(f\"\\nüèÜ –õ—É—á—à–∞—è –ø–æ {metric_name}:\")\n",
    "        print(f\"   –í–µ—Ä—Å–∏—è {best_row['–í–µ—Ä—Å–∏—è']} (Stage: {best_row['Stage']})\")\n",
    "        print(f\"   {metric_name}: {best_row[metric_name]:.4f}\")\n",
    "\n",
    "    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    # –ù–∞—Ö–æ–¥–∏–º –≤–µ—Ä—Å–∏—é —Å –ª—É—á—à–∏–º –±–∞–ª–∞–Ω—Å–æ–º –º–µ—Ç—Ä–∏–∫\n",
    "    df['Score'] = (df['ROC-AUC'] + df['F1-Score'] + df['Recall']) / 3\n",
    "    best_overall = df.loc[df['Score'].idxmax()]\n",
    "\n",
    "    print(f\"\\nüìä –õ—É—á—à–∞—è –≤–µ—Ä—Å–∏—è –ø–æ –æ–±—â–µ–º—É –±–∞–ª–∞–Ω—Å—É –º–µ—Ç—Ä–∏–∫:\")\n",
    "    print(f\"   –í–µ—Ä—Å–∏—è {best_overall['–í–µ—Ä—Å–∏—è']} (Stage: {best_overall['Stage']})\")\n",
    "    print(f\"   –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {best_overall['Score']:.4f}\")\n",
    "    print(f\"   ROC-AUC: {best_overall['ROC-AUC']:.4f}\")\n",
    "    print(f\"   F1-Score: {best_overall['F1-Score']:.4f}\")\n",
    "    print(f\"   Recall: {best_overall['Recall']:.4f}\")\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ª—É—á—à–∞—è –≤–µ—Ä—Å–∏—è Production\n",
    "    production_versions = df[df['Stage'] == 'Production']\n",
    "\n",
    "    if not production_versions.empty:\n",
    "        prod_version = production_versions.iloc[0]\n",
    "        if prod_version['–í–µ—Ä—Å–∏—è'] != best_overall['–í–µ—Ä—Å–∏—è']:\n",
    "            print(f\"\\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å (–≤–µ—Ä—Å–∏—è {best_overall['–í–µ—Ä—Å–∏—è']}) –Ω–µ –≤ Production!\")\n",
    "            print(f\"   –¢–µ–∫—É—â–∞—è Production –≤–µ—Ä—Å–∏—è: {prod_version['–í–µ—Ä—Å–∏—è']}\")\n",
    "            print(f\"   –†–∞–∑–Ω–∏—Ü–∞ –≤ ROC-AUC: {best_overall['ROC-AUC'] - prod_version['ROC-AUC']:.4f}\")\n",
    "            print(f\"\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ü–µ—Ä–µ–≤–µ–¥–∏—Ç–µ –≤–µ—Ä—Å–∏—é {best_overall['–í–µ—Ä—Å–∏—è']} –≤ Production\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ Production!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  –ù–µ—Ç –º–æ–¥–µ–ª–µ–π –≤ Production. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤–µ—Ä—Å–∏—é {best_overall['–í–µ—Ä—Å–∏—è']} –≤ Production\")\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ CSV\n",
    "    output_file = \"model_comparison.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"–ö–ê–ö –ò–ó–ú–ï–ù–ò–¢–¨ STAGE –ú–û–î–ï–õ–ò:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"\\n1. –ß–µ—Ä–µ–∑ MLflow UI (http://127.0.0.1:5001):\")\n",
    "    print(\"   - –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ Models ‚Üí churn_model_production\")\n",
    "    print(\"   - –í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—É—é –≤–µ—Ä—Å–∏—é\")\n",
    "    print(\"   - –ù–∞–∂–º–∏—Ç–µ –Ω–∞ Stage –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å\")\n",
    "    print(\"\\n2. –ß–µ—Ä–µ–∑ Python API:\")\n",
    "    print(f\"\"\"\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤–µ—Ä—Å–∏—é {best_overall['–í–µ—Ä—Å–∏—è']} –≤ Production\n",
    "client.transition_model_version_stage(\n",
    "    name=\"{REGISTRY_MODEL_NAME}\",\n",
    "    version=\"{best_overall['–í–µ—Ä—Å–∏—è']}\",\n",
    "    stage=\"Production\"\n",
    ")\n",
    "\n",
    "# –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—É—é Production –≤–µ—Ä—Å–∏—é\n",
    "client.transition_model_version_stage(\n",
    "    name=\"{REGISTRY_MODEL_NAME}\",\n",
    "    version=\"2\",  # –Ω–æ–º–µ—Ä —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏\n",
    "    stage=\"Archived\"\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n–û–®–ò–ë–ö–ê: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b303a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –≤ MLflow Model Registry\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    log_loss,\n",
    "    classification_report\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"–û–ë–£–ß–ï–ù–ò–ï –ù–û–í–û–ô –í–ï–†–°–ò–ò –ú–û–î–ï–õ–ò\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL\n",
    "print(\"\\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...\")\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"\\n2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "X = df.drop(['customer_id', 'begin_date', 'end_date', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "X = X.fillna('Missing')\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"   Train: {len(X_train)} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   Test: {len(X_test)} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ test: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏\n",
    "for col in cat_features:\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "print(f\"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(cat_features)}\")\n",
    "print(f\"   –ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(X_train.columns) - len(cat_features)}\")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "print(\"\\n3. –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏ CatBoost...\")\n",
    "print(\"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "print(\"   - iterations: 300\")\n",
    "print(\"   - depth: 8\")\n",
    "print(\"   - learning_rate: 0.03\")\n",
    "print(\"   - l2_leaf_reg: 3\")\n",
    "print(\"   - random_strength: 1\")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=8,\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=3,\n",
    "    random_strength=1,\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    cat_features=cat_features,\n",
    "    eval_metric='AUC'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "print(\"   ‚úì –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!\")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "print(\"\\n4. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "print(\"\\n5. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...\")\n",
    "\n",
    "# Confusion Matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "metrics = {\n",
    "    # Classification metrics\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_proba)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"f1_score\": float(f1_score(y_test, y_pred)),\n",
    "    \"log_loss\": float(log_loss(y_test, y_proba)),\n",
    "\n",
    "    # Confusion Matrix metrics\n",
    "    \"true_negatives\": int(tn),\n",
    "    \"false_positives\": int(fp),\n",
    "    \"false_negatives\": int(fn),\n",
    "    \"true_positives\": int(tp),\n",
    "\n",
    "    # Error rates\n",
    "    \"false_positive_rate\": float(fp / (fp + tn)),\n",
    "    \"false_negative_rate\": float(fn / (fn + tp)),\n",
    "\n",
    "    # Additional metrics\n",
    "    \"specificity\": float(tn / (tn + fp)),\n",
    "    \"negative_predictive_value\": float(tn / (tn + fn)) if (tn + fn) > 0 else 0.0,\n",
    "}\n",
    "\n",
    "print(\"\\n   –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
    "print(f\"   - Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "print(f\"   - ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
    "print(f\"   - Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"   - Recall:    {metrics['recall']:.4f}\")\n",
    "print(f\"   - F1-Score:  {metrics['f1_score']:.4f}\")\n",
    "print(f\"   - Log Loss:  {metrics['log_loss']:.4f}\")\n",
    "\n",
    "print(\"\\n   Confusion Matrix:\")\n",
    "print(f\"   - True Negatives:  {metrics['true_negatives']}\")\n",
    "print(f\"   - False Positives: {metrics['false_positives']}\")\n",
    "print(f\"   - False Negatives: {metrics['false_negatives']}\")\n",
    "print(f\"   - True Positives:  {metrics['true_positives']}\")\n",
    "\n",
    "print(\"\\n   –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\")\n",
    "print(f\"   - False Positive Rate: {metrics['false_positive_rate']:.4f}\")\n",
    "print(f\"   - False Negative Rate: {metrics['false_negative_rate']:.4f}\")\n",
    "print(f\"   - Specificity:         {metrics['specificity']:.4f}\")\n",
    "print(f\"   - NPV:                 {metrics['negative_predictive_value']:.4f}\")\n",
    "\n",
    "# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow\n",
    "print(\"\\n6. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ MLflow...\")\n",
    "EXPERIMENT_NAME = \"churn_fio\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_production\"\n",
    "RUN_NAME = \"Model v3 (optimized)\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # –¢–µ–≥–∏ –¥–ª—è –ª—É—á—à–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\n",
    "    mlflow.set_tags({\n",
    "        \"model_version\": \"v3\",\n",
    "        \"business_objective\": \"churn_prediction\",\n",
    "        \"target_metric\": \"roc_auc\",\n",
    "        \"prediction_horizon\": \"30_days\",\n",
    "        \"data_period\": \"2024-Q4\",\n",
    "        \"feature_version\": \"v3.2\",\n",
    "        \"deployment_ready\": \"true\",\n",
    "        \"model_type\": \"CatBoost\",\n",
    "        \"training_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
    "    })\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "    params = {\n",
    "        \"iterations\": 300,\n",
    "        \"depth\": 8,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"l2_leaf_reg\": 3,\n",
    "        \"random_strength\": 1,\n",
    "        \"random_seed\": 42,\n",
    "        \"test_size\": 0.2,\n",
    "        \"cat_features_count\": len(cat_features),\n",
    "        \"numeric_features_count\": len(X_train.columns) - len(cat_features)\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É –º–æ–¥–µ–ª–∏\n",
    "    signature = mlflow.models.infer_signature(X_test, y_pred)\n",
    "    input_example = X_test[:10]\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        pip_requirements=[\n",
    "            \"catboost==1.2.2\",\n",
    "            \"scikit-learn==1.3.1\",\n",
    "            \"pandas==2.0.1\",\n",
    "            \"numpy\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º classification report –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç\n",
    "    report = classification_report(y_test, y_pred, target_names=['No Churn', 'Churn'])\n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    os.remove(\"classification_report.txt\")\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    model_version = model_info.registered_model_version\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "    description = \"\"\"Optimized model with advanced hyperparameters:\n",
    "- Deeper trees (depth=8) for better pattern recognition\n",
    "- More iterations (300) for improved convergence\n",
    "- Lower learning rate (0.03) for stable training\n",
    "- Added regularization (l2_leaf_reg=3) to prevent overfitting\n",
    "- Random strength for better generalization\n",
    "\n",
    "This version shows improved metrics across all key indicators.\n",
    "\"\"\"\n",
    "\n",
    "    client.update_model_version(\n",
    "        name=REGISTRY_MODEL_NAME,\n",
    "        version=model_version,\n",
    "        description=description\n",
    "    )\n",
    "\n",
    "    print(f\"\\n   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∫–∞–∫ –≤–µ—Ä—Å–∏—è {model_version}\")\n",
    "    print(f\"   Run ID: {run_id}\")\n",
    "    print(f\"   Model URI: {model_info.model_uri}\")\n",
    "\n",
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –≤–µ—Ä—Å–∏—è–º–∏\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"–°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ò–ú–ò –í–ï–†–°–ò–Ø–ú–ò\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    versions = client.search_model_versions(f\"name='{REGISTRY_MODEL_NAME}'\")\n",
    "\n",
    "    print(f\"\\n–í—Å–µ–≥–æ –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏: {len(versions)}\")\n",
    "    print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤–µ—Ä—Å–∏—è–º:\")\n",
    "\n",
    "    version_metrics = []\n",
    "    for version in sorted(versions, key=lambda x: int(x.version)):\n",
    "        run = client.get_run(version.run_id)\n",
    "        version_metrics.append({\n",
    "            'version': version.version,\n",
    "            'stage': version.current_stage,\n",
    "            'roc_auc': run.data.metrics.get('roc_auc', run.data.metrics.get('auc', 0)),\n",
    "            'f1_score': run.data.metrics.get('f1_score', run.data.metrics.get('f1', 0)),\n",
    "            'precision': run.data.metrics.get('precision', 0),\n",
    "            'recall': run.data.metrics.get('recall', 0),\n",
    "        })\n",
    "\n",
    "    print(\"\\n{:<10} {:<15} {:<12} {:<12} {:<12} {:<12}\".format(\n",
    "        \"–í–µ—Ä—Å–∏—è\", \"Stage\", \"ROC-AUC\", \"F1-Score\", \"Precision\", \"Recall\"\n",
    "    ))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for vm in version_metrics:\n",
    "        print(\"{:<10} {:<15} {:<12.4f} {:<12.4f} {:<12.4f} {:<12.4f}\".format(\n",
    "            vm['version'],\n",
    "            vm['stage'] if vm['stage'] else 'None',\n",
    "            vm['roc_auc'],\n",
    "            vm['f1_score'],\n",
    "            vm['precision'],\n",
    "            vm['recall']\n",
    "        ))\n",
    "\n",
    "    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –≤–µ—Ä—Å–∏—é –ø–æ ROC-AUC\n",
    "    best_version = max(version_metrics, key=lambda x: x['roc_auc'])\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"üèÜ –õ–£–ß–®–ê–Ø –í–ï–†–°–ò–Ø –ü–û ROC-AUC: –í–µ—Ä—Å–∏—è {best_version['version']}\")\n",
    "    print(f\"   ROC-AUC: {best_version['roc_auc']:.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –≤–µ—Ä—Å–∏–π: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"–°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1. –û—Ç–∫—Ä–æ–π—Ç–µ MLflow UI: http://127.0.0.1:5001\")\n",
    "print(\"\\n2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª 'Models' –∏ –Ω–∞–π–¥–∏—Ç–µ 'churn_model_production'\")\n",
    "print(\"\\n3. –°—Ä–∞–≤–Ω–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏\")\n",
    "print(\"\\n4. –ï—Å–ª–∏ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –ª—É—á—à–µ, –ø–µ—Ä–µ–≤–µ–¥–∏—Ç–µ –µ—ë –≤ Production:\")\n",
    "print(f\"   - –û—Ç–∫—Ä–æ–π—Ç–µ –≤–µ—Ä—Å–∏—é {model_version}\")\n",
    "print(\"   - –ù–∞–∂–º–∏—Ç–µ 'Stage: None' –∏ –≤—ã–±–µ—Ä–∏—Ç–µ 'Production'\")\n",
    "print(\"   - –ü—Ä–µ–¥—ã–¥—É—â—É—é Production –≤–µ—Ä—Å–∏—é –º–æ–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤ Archived\")\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e659b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ MLflow\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"–û–ë–£–ß–ï–ù–ò–ï –ò –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –í MLFLOW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL\n",
    "print(\"\\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...\")\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"\\n2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "# –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "X = df.drop(['customer_id', 'begin_date', 'end_date', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "X = X.fillna('Missing')\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"   Train: {len(X_train)} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   Test: {len(X_test)} —Å—Ç—Ä–æ–∫\")\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏)\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏\n",
    "for col in cat_features:\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "print(f\"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(cat_features)}\")\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "print(\"\\n3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ CatBoost...\")\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"   –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!\")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "print(\"\\n4. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...\")\n",
    "prediction = model.predict(X_test)\n",
    "probas = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "print(\"\\n5. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...\")\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, prediction).ravel()\n",
    "err1 = fp / (tn + fp + fn + tp)  # False Positive Rate\n",
    "err2 = fn / (tn + fp + fn + tp)  # False Negative Rate\n",
    "\n",
    "metrics = {\n",
    "    \"err1\": float(err1),\n",
    "    \"err2\": float(err2),\n",
    "    \"auc\": float(roc_auc_score(y_test, probas)),\n",
    "    \"precision\": float(precision_score(y_test, prediction)),\n",
    "    \"recall\": float(recall_score(y_test, prediction)),\n",
    "    \"f1\": float(f1_score(y_test, prediction)),\n",
    "    \"logloss\": float(log_loss(y_test, prediction))\n",
    "}\n",
    "\n",
    "print(f\"   AUC: {metrics['auc']:.4f}\")\n",
    "print(f\"   F1: {metrics['f1']:.4f}\")\n",
    "print(f\"   Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"   Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow\n",
    "print(\"\\n6. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ MLflow...\")\n",
    "EXPERIMENT_NAME = \"churn_fio\"\n",
    "RUN_NAME = \"catboost_model_v1\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "    mlflow.log_params({\n",
    "        \"iterations\": 100,\n",
    "        \"depth\": 6,\n",
    "        \"learning_rate\": 0.1\n",
    "    })\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É –º–æ–¥–µ–ª–∏\n",
    "    signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "    input_example = X_test[:10]\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"catboost\",\n",
    "            \"scikit-learn\",\n",
    "            \"pandas\",\n",
    "            \"numpy\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"   Run ID: {run_id}\")\n",
    "    print(f\"   Model URI: {model_info.model_uri}\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "bucket_name = os.getenv(\"S3_BUCKET_NAME\")\n",
    "s3_path = f\"s3://{bucket_name}/{experiment.experiment_id}/{run_id}/artifacts/models\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì –ì–û–¢–û–í–û!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤ S3:\")\n",
    "print(s3_path)\n",
    "print(\"\\n–≠—Ç–æ—Ç –ø—É—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç:\")\n",
    "print(\"  - MLmodel\")\n",
    "print(\"  - model.cb\")\n",
    "print(\"  - conda.yaml\")\n",
    "print(\"  - python_env.yaml\")\n",
    "print(\"  - requirements.txt\")\n",
    "print(\"  - input_example.json\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏ –≤ Production –∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"–ü–ï–†–ï–í–û–î –ú–û–î–ï–õ–ò –í PRODUCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "REGISTRY_MODEL_NAME = \"churn_model_production\"\n",
    "NEW_PRODUCTION_VERSION = \"3\"\n",
    "OLD_PRODUCTION_VERSION = \"2\"\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–µ—Ä—Å–∏—è—Ö –¥–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "    print(\"\\n–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–µ—Ä—Å–∏–π:\")\n",
    "    versions = client.search_model_versions(f\"name='{REGISTRY_MODEL_NAME}'\")\n",
    "    for version in sorted(versions, key=lambda x: int(x.version)):\n",
    "        print(f\"  –í–µ—Ä—Å–∏—è {version.version}: Stage = {version.current_stage or 'None'}\")\n",
    "\n",
    "    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤–µ—Ä—Å–∏—é 3 –≤ Production\n",
    "    print(f\"\\n1. –ü–µ—Ä–µ–≤–æ–¥ –≤–µ—Ä—Å–∏–∏ {NEW_PRODUCTION_VERSION} –≤ Production...\")\n",
    "    client.transition_model_version_stage(\n",
    "        name=REGISTRY_MODEL_NAME,\n",
    "        version=NEW_PRODUCTION_VERSION,\n",
    "        stage=\"Production\",\n",
    "        archive_existing_versions=False\n",
    "    )\n",
    "    print(f\"   ‚úÖ –í–µ—Ä—Å–∏—è {NEW_PRODUCTION_VERSION} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ Production\")\n",
    "\n",
    "    # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Å—Ç–∞—Ä—É—é Production –≤–µ—Ä—Å–∏—é\n",
    "    print(f\"\\n2. –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ {OLD_PRODUCTION_VERSION}...\")\n",
    "    client.transition_model_version_stage(\n",
    "        name=REGISTRY_MODEL_NAME,\n",
    "        version=OLD_PRODUCTION_VERSION,\n",
    "        stage=\"Archived\"\n",
    "    )\n",
    "    print(f\"   ‚úÖ –í–µ—Ä—Å–∏—è {OLD_PRODUCTION_VERSION} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ Archived\")\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"–ù–û–í–û–ï –°–û–°–¢–û–Ø–ù–ò–ï –í–ï–†–°–ò–ô\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    versions = client.search_model_versions(f\"name='{REGISTRY_MODEL_NAME}'\")\n",
    "    for version in sorted(versions, key=lambda x: int(x.version)):\n",
    "        run = client.get_run(version.run_id)\n",
    "        roc_auc = run.data.metrics.get('roc_auc', run.data.metrics.get('auc', 0))\n",
    "        f1 = run.data.metrics.get('f1_score', run.data.metrics.get('f1', 0))\n",
    "\n",
    "        stage_emoji = \"üè≠\" if version.current_stage == \"Production\" else \"üß™\" if version.current_stage == \"Staging\" else \"üì¶\" if version.current_stage == \"Archived\" else \"üìÑ\"\n",
    "\n",
    "        print(f\"\\n{stage_emoji} –í–µ—Ä—Å–∏—è {version.version}:\")\n",
    "        print(f\"   Stage: {version.current_stage or 'None'}\")\n",
    "        print(f\"   ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"   F1-Score: {f1:.4f}\")\n",
    "        print(f\"   Run ID: {version.run_id[:16]}...\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ –£–°–ü–ï–®–ù–û!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n–ú–æ–¥–µ–ª—å –≤–µ—Ä—Å–∏–∏ {NEW_PRODUCTION_VERSION} —Ç–µ–ø–µ—Ä—å –≤ Production!\")\n",
    "    print(\"\\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:\")\n",
    "    print(f\"\"\"\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ Production\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    \"models:/churn_model_production/Production\"\n",
    ")\n",
    "\n",
    "# –ò–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–∏\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    \"models:/churn_model_production/{NEW_PRODUCTION_VERSION}\"\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "predictions = model.predict(data)\n",
    "\"\"\")\n",
    "\n",
    "    print(\"\\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤ MLflow UI: http://127.0.0.1:5001\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û–®–ò–ë–ö–ê: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeaae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ Production\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PRODUCTION –ú–û–î–ï–õ–ò\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ Production\n",
    "print(\"\\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ Production...\")\n",
    "model_uri = \"models:/churn_model_production/Production\"\n",
    "print(f\"   URI: {model_uri}\")\n",
    "\n",
    "try:\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    print(\"   ‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 2. –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏\n",
    "print(\"\\n2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:\")\n",
    "client = MlflowClient()\n",
    "production_versions = client.get_latest_versions(\"churn_model_production\", stages=[\"Production\"])\n",
    "\n",
    "if production_versions:\n",
    "    prod_version = production_versions[0]\n",
    "    print(f\"   –í–µ—Ä—Å–∏—è: {prod_version.version}\")\n",
    "    print(f\"   Stage: {prod_version.current_stage}\")\n",
    "    print(f\"   Run ID: {prod_version.run_id}\")\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    run = client.get_run(prod_version.run_id)\n",
    "    print(f\"\\n   –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏:\")\n",
    "    print(f\"   - ROC-AUC:   {run.data.metrics.get('roc_auc', 0):.4f}\")\n",
    "    print(f\"   - F1-Score:  {run.data.metrics.get('f1_score', 0):.4f}\")\n",
    "    print(f\"   - Precision: {run.data.metrics.get('precision', 0):.4f}\")\n",
    "    print(f\"   - Recall:    {run.data.metrics.get('recall', 0):.4f}\")\n",
    "    print(f\"   - Accuracy:  {run.data.metrics.get('accuracy', 0):.4f}\")\n",
    "\n",
    "# 3. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "print(\"\\n3. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM users_churn LIMIT 10\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)\n",
    "X_test = df.drop(['customer_id', 'begin_date', 'end_date', 'target'], axis=1)\n",
    "y_test = df['target']\n",
    "X_test = X_test.fillna('Missing')\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏\n",
    "cat_features = X_test.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in cat_features:\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "print(f\"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_test.shape[1]}\")\n",
    "\n",
    "# 4. –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "print(\"\\n4. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...\")\n",
    "try:\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"   ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—É—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!\")\n",
    "    print(f\"\\n   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–µ—Ä–≤—ã—Ö 10 –∫–ª–∏–µ–Ω—Ç–æ–≤:\")\n",
    "    print(f\"   {'Customer ID':<15} {'–†–µ–∞–ª—å–Ω—ã–π':<10} {'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ':<15} {'–°—Ç–∞—Ç—É—Å'}\")\n",
    "    print(\"   \" + \"-\" * 60)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        customer_id = row['customer_id']\n",
    "        actual = y_test.iloc[idx]\n",
    "        predicted = predictions[idx]\n",
    "        status = \"‚úÖ –í–µ—Ä–Ω–æ\" if actual == predicted else \"‚ùå –û—à–∏–±–∫–∞\"\n",
    "\n",
    "        print(f\"   {customer_id:<15} {actual:<10} {predicted:<15} {status}\")\n",
    "\n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    correct = sum(y_test == predictions)\n",
    "    total = len(y_test)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"\\n   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:\")\n",
    "    print(f\"   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {correct}/{total}\")\n",
    "    print(f\"   - –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∏\n",
    "print(\"\\n5. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∑–∞–≥—Ä—É–∑–∫–∏:\")\n",
    "\n",
    "# –ü–æ –≤–µ—Ä—Å–∏–∏\n",
    "print(\"\\n   a) –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ –Ω–æ–º–µ—Ä—É –≤–µ—Ä—Å–∏–∏:\")\n",
    "model_by_version = mlflow.pyfunc.load_model(\"models:/churn_model_production/3\")\n",
    "print(\"      ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å –≤–µ—Ä—Å–∏–∏ 3\")\n",
    "\n",
    "# –ü–æ stage\n",
    "print(\"\\n   b) –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ stage:\")\n",
    "model_by_stage = mlflow.pyfunc.load_model(\"models:/churn_model_production/Production\")\n",
    "print(\"      ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ Production –º–æ–¥–µ–ª—å\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nProduction –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!\")\n",
    "print(\"\\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ:\")\n",
    "print(\"\"\"\n",
    "import mlflow\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ Production –º–æ–¥–µ–ª–∏\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    \"models:/churn_model_production/Production\"\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "predictions = model.predict(your_data)\n",
    "\"\"\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
