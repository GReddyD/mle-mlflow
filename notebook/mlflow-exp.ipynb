{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f453c0e",
   "metadata": {},
   "outputs": [],
   "source": "# делаем import необходимых библиотек\nimport os\nimport mlflow\n\n# устанавливаем локальное хранилище для наших экспериментов\n# хранилище должно быть такое же, как и при запуске сервиса\nmlflow.set_tracking_uri('file:./mlflow_experiments_store')\n\n# получаем id эксеримента, который создаётся по умолчанию\n# эксперимент по умолчанию называется Default\nexperiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n\n# залогируем тестовую метрику и артефакт\nwith mlflow.start_run(run_name='Default', experiment_id=experiment_id) as run:\n    run_id = run.info.run_id\n    mlflow.log_metric(\"test_metric\", 0)\n    mlflow.log_artifact(\"../test_artifact.txt\", \"test_artifact\")  # исправлен путь\n\nprint(f\"Run id запуска: {run_id}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0262d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_metric\n"
     ]
    }
   ],
   "source": [
    "!ls mlflow_experiments_store/0/{run_id}/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391ca5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_artifact\n"
     ]
    }
   ],
   "source": [
    "!cat mlflow_experiments_store/0/{run_id}/artifacts/test_artifact/test_artifact.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240ca43",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport mlflow\n\nmlflow.set_tracking_uri('http://0.0.0.0:5001')  # изменено с 5000 на 5001\n\n# получаем id эксперимента, который создаётся по умолчанию\n# эксперимент по умолчанию называется Default\nexperiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n\nwith mlflow.start_run(run_name=\"Default\", experiment_id=experiment_id) as run:\n    run_id = run.info.run_id\n    \n    mlflow.log_metric(\"test_metric_sqlite\", 0)\n    mlflow.log_artifact(\"../test_artifact.txt\", \"test_artifact\")  # исправлен путь\n\n# проверим, что наши данные сохранились в локальной папке, а также создалась база данных SQLite\nassert os.path.exists(\"../mlflow_experiments_store_sqlite\")  # исправлен путь\nassert os.path.exists(\"../mydb.sqlite\")  # исправлен путь"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d432a32",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport mlflow\nfrom dotenv import load_dotenv\n\n# Загружаем переменные окружения из .env файла\nload_dotenv('../.env')\n\n# определяем основные credentials, которые нужны для подключения к MLflow\n# важно, что credentials мы передаём для себя как пользователей Tracking Service\n# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\nos.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n\n# Проверяем, что все переменные загружены\nassert os.getenv(\"S3_ACCESS_KEY\") is not None, \"S3_ACCESS_KEY не найден в .env\"\nassert os.getenv(\"S3_SECRET_KEY\") is not None, \"S3_SECRET_KEY не найден в .env\"\n\n# определяем глобальные переменные\n# поднимаем MLflow локально\nTRACKING_SERVER_HOST = \"127.0.0.1\"\nTRACKING_SERVER_PORT = 5001  # изменено с 5000 на 5001\n\nYOUR_NAME = \"ALEKSANDR\" # введите своё имя для создания уникального эксперимента\nassert YOUR_NAME, \"ALEKSANDR\"\n\n# название тестового эксперимента и запуска (run) внутри него\nEXPERIMENT_NAME = f\"test_connection_experiment_{YOUR_NAME}\"\nRUN_NAME = \"test_connection_run\"\n\n# тестовые данные\nMETRIC_NAME = \"test_metric\"\nMETRIC_VALUE = 0\n\n# устанавливаем host, который будет отслеживать наши эксперименты\nmlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n\n# создаём тестовый эксперимент и записываем в него тестовую информацию\nexperiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\nwith mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n    run_id = run.info.run_id\n    \n    mlflow.log_metric(METRIC_NAME, METRIC_VALUE)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fbbf9",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport pandas as pd\nimport psycopg\nfrom dotenv import load_dotenv\n\n# Загружаем переменные окружения из .env файла\nload_dotenv('../.env')\n\nconnection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\npostgres_credentials = {\n    \"host\": os.getenv(\"DB_DESTINATION_HOST\"), \n    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n}\nassert all([var_value is not None and var_value != \"\" for var_value in list(postgres_credentials.values())]), \"Не все переменные окружения установлены\"\n\nconnection.update(postgres_credentials)\n\n# определим название таблицы, в которой хранятся наши данные.\nTABLE_NAME = \"users_churn\"\n\n# эта конструкция создаёт контекстное управление для соединения с базой данных \n# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\nwith psycopg.connect(**connection) as conn:\n\n# создаёт объект курсора для выполнения запросов к базе данных\n# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n    with conn.cursor() as cur:\n        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n                \n                # извлекаем все строки, полученные в результате выполнения запроса\n        data = cur.fetchall()\n\n                # получает список имён столбцов из объекта курсора\n        columns = [col[0] for col in cur.description]\n\n# создаёт объект DataFrame из полученных данных и имён столбцов. \n# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\ndf = pd.DataFrame(data, columns=columns)"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63137f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Название колонок вашего датафрейма запишите в текстовый файл\n",
    "with open(\"columns.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "    fio.write(\",\".join(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d62d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_columns = [\n",
    "    \"type\", \"paperless_billing\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "    \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\",\n",
    "    \"multiple_lines\", \"target\"\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for col in counts_columns:\n",
    "    column_stat = df[col].value_counts().to_dict()\n",
    "    column_stat = {f\"{col}_{key}\": int(value) for key, value in column_stat.items()}\n",
    "    stats.update(column_stat)\n",
    "\n",
    "stats[\"data_length\"] = int(df.shape[0])\n",
    "stats[\"monthly_charges_min\"] = float(df[\"monthly_charges\"].min())\n",
    "stats[\"monthly_charges_max\"] = float(df[\"monthly_charges\"].max())\n",
    "stats[\"monthly_charges_mean\"] = float(df[\"monthly_charges\"].mean())\n",
    "stats[\"monthly_charges_median\"] = float(df[\"monthly_charges\"].median())\n",
    "stats[\"total_charges_min\"] = float(df[\"total_charges\"].min())\n",
    "stats[\"total_charges_max\"] = float(df[\"total_charges\"].max())\n",
    "stats[\"total_charges_mean\"] = float(df[\"total_charges\"].mean())\n",
    "stats[\"total_charges_median\"] = float(df[\"total_charges\"].median())\n",
    "stats[\"unique_customers_number\"] = int(df[\"customer_id\"].nunique())\n",
    "stats[\"end_date_nan\"] = int(df[\"end_date\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e469607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccf9ed",
   "metadata": {},
   "outputs": [],
   "source": "import mlflow\nimport os\n\n# Подключаемся к MLflow серверу\nmlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n\n# задаём название эксперимента и имя запуска для логирования в MLflow\nEXPERIMENT_NAME = \"churn_fio\"\nRUN_NAME = \"data_check\"\n\n# устанавливаем эксперимент (создаёт новый или использует существующий)\nmlflow.set_experiment(EXPERIMENT_NAME)\n\nwith mlflow.start_run(run_name=RUN_NAME) as run:\n    # получаем уникальный идентификатор запуска эксперимента\n    run_id = run.info.run_id\n    \n    # логируем метрики эксперимента\n    mlflow.log_metrics(stats)\n    \n    # логируем файлы как артефакты эксперимента\n    mlflow.log_artifact(\"columns.txt\", artifact_path=\"dataframe\")\n    mlflow.log_artifact(\"users_churn.csv\", artifact_path=\"dataframe\")\n\nexperiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n# получаем данные о запуске эксперимента по его уникальному идентификатору\nrun = mlflow.get_run(run_id)\n\n# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\nassert run.info.status == \"FINISHED\"\n\n# удаляем файлы\nos.remove(\"columns.txt\")\nos.remove(\"users_churn.csv\")"
  },
  {
   "cell_type": "markdown",
   "id": "a3b538ac",
   "metadata": {},
   "source": [
    "## Логируем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11701100",
   "metadata": {},
   "source": [
    "Обычно, помимо самой модели, логируются и метрики качества модели. Для этого оценим, насколько хорошо модель делает предсказания, и сохраним эти метрики. Предсказанные значения хранятся в переменной prediction, а реальные значения в y_test.\n",
    "Начнём с вычисления метрик, используя модуль sklearn.metrics. Оцените метрики:\n",
    "ROC-AUC,\n",
    "F1-мера,\n",
    "точность — precision,\n",
    "полнота recall,\n",
    "матрица ошибок — confusion_matrix,\n",
    "logloss, которая показывает логарифмические потери.\n",
    "Значения этих метрик запишите в словарь metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "597ede5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# посчитайте метрики из модуля sklearn.metrics\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# err_1 — ошибка первого рода (False Positive)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# err_2 — ошибка второго рода (False Negative)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m _, err1, _, err2 \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43my_test\u001b[49m, prediction, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     17\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, probas)\n\u001b[1;32m     18\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, prediction)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "# заведите словарь со всеми метриками\n",
    "metrics = {}\n",
    "\n",
    "# посчитайте метрики из модуля sklearn.metrics\n",
    "# err_1 — ошибка первого рода (False Positive)\n",
    "# err_2 — ошибка второго рода (False Negative)\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# запишите значения метрик в словарь\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172ae71",
   "metadata": {},
   "source": [
    "Разверните сервер для запуска MLflow с хранилищем экспериментов и артефактов. Не забудьте про модуль Model Registry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export MLFLOW_S3_ENDPOINT_URL=https://storage.yandexcloud.net\n",
    "export AWS_ACCESS_KEY_ID=$S3_ACCESS_KEY\n",
    "export AWS_SECRET_ACCESS_KEY=$S3_SECRET_KEY\n",
    "\n",
    "mlflow server \\\n",
    "    --backend-store-uri postgresql://mle_20250507_39f5f3ff21_freetrack:76bc4e5fcfcd46cd8da35b17e6d24263@rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net:6432/playground_mle_20250507_39f5f3ff21 \\\n",
    "    --registry-store-uri postgresql://mle_20250507_39f5f3ff21_freetrack:76bc4e5fcfcd46cd8da35b17e6d24263@rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net:6432/playground_mle_20250507_39f5f3ff21 \\\n",
    "    --default-artifact-root s3://s3-student-mle-20250507-39f5f3ff21-freetrack \\\n",
    "    --no-serve-artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca79b2",
   "metadata": {},
   "source": [
    "Зарегистрируйте вашу базовую модель в реестре моделей с полученным словарём метрик.\n",
    "Используйте существующий эксперимент EXPERIMENT_NAME и новый запуск RUN_NAME.\n",
    "Имя зарегистрированной модели сохраните в переменную REGISTRY_MODEL_NAME.\n",
    "Окружение проекта сформируйте в файле requirements.txt.\n",
    "Сформируйте сигнатуру модели из тестовых данных и предсказания модели.\n",
    "Добавьте мета-информацию, которую считаете важной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0406887",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport mlflow\nfrom dotenv import load_dotenv\n\n# Загружаем переменные окружения из .env файла\nload_dotenv('../.env')\n\nEXPERIMENT_NAME = \"churn_prediction_stepanov\"  # ваше уникальное имя эксперимента\nRUN_NAME = \"model_0_registry\"\nREGISTRY_MODEL_NAME = \"churn_model_nikolaistepanov\"\n\n\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\nos.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\")\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\")\n\n# Настройка MLflow tracking и registry URI\nmlflow.set_tracking_uri(\"http://127.0.0.1:5001\")  # изменено с 5000 на 5001\nmlflow.set_registry_uri(\"http://127.0.0.1:5001\")  # изменено с 5000 на 5001\n\n\npip_requirements = '../requirements.txt'\nsignature = mlflow.models.infer_signature(X_test, prediction)\ninput_example = X_test[:10]\nmetadata = {'model_type': 'monthly'}\n\n\nexperiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n\nwith mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n    run_id = run.info.run_id\n    \n    # Логируем метрики\n    mlflow.log_metrics(metrics)\n    \n    # Логируем и регистрируем модель\n    model_info = mlflow.catboost.log_model(\n        cb_model=model,\n        artifact_path=\"models\",\n        registered_model_name=REGISTRY_MODEL_NAME,\n        pip_requirements=pip_requirements,\n        signature=signature,\n        input_example=input_example,\n        metadata=metadata,\n        await_registration_for=60\n    )"
  },
  {
   "cell_type": "markdown",
   "id": "027eeba2",
   "metadata": {},
   "source": [
    "Достаньте модель из реестра и с её помощью сделайте предсказание на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730f4f9",
   "metadata": {},
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\n",
    "model_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "assert model_predictions.dtype == int\n",
    "\n",
    "print(model_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112799b",
   "metadata": {},
   "source": [
    "Создание эксперемента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4253f88",
   "metadata": {},
   "outputs": [],
   "source": "import mlflow\n\n# Подключаемся к MLflow серверу\nmlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n\nEXPERIMENT_NAME = \"my_own_experiment\"\n\n# Проверяем, существует ли эксперимент\nexperiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n\nif experiment is None:\n    # Создаем новый эксперимент\n    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\nelse:\n    # Используем существующий\n    experiment_id = experiment.experiment_id\n\nprint(f\"Experiment ID: {experiment_id}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1831c",
   "metadata": {},
   "outputs": [],
   "source": "import mlflow\n\n# Подключаемся к MLflow серверу\nmlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n\nexperiments = mlflow.search_experiments()\n\nprint(\"Доступные эксперименты с количеством runs:\")\nprint(\"=\" * 60)\nfor exp in experiments:\n    runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n    print(f\"Name: {exp.name}\")\n    print(f\"ID: {exp.experiment_id}\")\n    print(f\"Runs count: {len(runs)}\")\n    print(\"-\" * 60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}