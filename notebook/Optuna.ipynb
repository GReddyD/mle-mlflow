{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_markdown",
   "metadata": {},
   "source": [
    "# –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å Optuna\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ CatBoost —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Optuna –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ TPE (Tree-structured Parzen Estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "TRACKING_SERVER_HOST = \"localhost\"\n",
    "TRACKING_SERVER_PORT = 5001\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow\n",
    "mlflow_tracking_uri = f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\"\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_registry_uri(mlflow_tracking_uri)\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"S3_ACCESS_KEY\", \"\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"S3_SECRET_KEY\", \"\")\n",
    "\n",
    "EXPERIMENT_NAME = \"catboost_hyperparameter_tuning\"\n",
    "RUN_NAME = \"model_bayesian_search\"\n",
    "STUDY_DB_NAME = \"sqlite:///optuna_study.db\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "STUDY_NAME = f\"churn_model_{timestamp}\"\n",
    "\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Optuna Study DB: {STUDY_DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_loading_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "TABLE_NAME = \"users_churn\"\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_preparation_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "columns_to_drop = ['id', 'customer_id', 'begin_date', 'end_date']\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "label_encoders = {}\n",
    "categorical_columns = df_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "X = df_clean.drop('target', axis=1)\n",
    "y = df_clean['target']\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ X_train: {X_train.shape}\")\n",
    "print(f\"‚úÖ X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective_function_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è parent run\n",
    "parent_run_id = None\n",
    "experiment_id = None\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    global parent_run_id, experiment_id\n",
    "    \n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.1, 5),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 5),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"task_type\": \"CPU\",\n",
    "        \"random_seed\": 0,\n",
    "        \"iterations\": 300,\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=2)\n",
    "    metrics = defaultdict(list)\n",
    "    \n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        train_x = X_train.iloc[train_index]\n",
    "        train_y = y_train.iloc[train_index]\n",
    "        val_x = X_train.iloc[val_index]\n",
    "        val_y = y_train.iloc[val_index]\n",
    "        \n",
    "        model = CatBoostClassifier(**param)\n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        prediction = model.predict(val_x)\n",
    "        probas = model.predict_proba(val_x)[:, 1]\n",
    "        \n",
    "        cm = confusion_matrix(val_y, prediction, normalize='all')\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        err1 = fp\n",
    "        err2 = fn\n",
    "        \n",
    "        auc = roc_auc_score(val_y, probas)\n",
    "        precision = precision_score(val_y, prediction)\n",
    "        recall = recall_score(val_y, prediction)\n",
    "        f1 = f1_score(val_y, prediction)\n",
    "        logloss = log_loss(val_y, probas)\n",
    "        \n",
    "        metrics[\"err1\"].append(err1)\n",
    "        metrics[\"err2\"].append(err2)\n",
    "        metrics[\"auc\"].append(auc)\n",
    "        metrics[\"precision\"].append(precision)\n",
    "        metrics[\"recall\"].append(recall)\n",
    "        metrics[\"f1\"].append(f1)\n",
    "        metrics[\"logloss\"].append(logloss)\n",
    "    \n",
    "    # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    err_1 = np.median(np.array(metrics['err1']))\n",
    "    err_2 = np.median(np.array(metrics['err2']))\n",
    "    auc = np.median(np.array(metrics['auc']))\n",
    "    precision = np.median(np.array(metrics['precision']))\n",
    "    recall = np.median(np.array(metrics['recall']))\n",
    "    f1 = np.median(np.array(metrics['f1']))\n",
    "    logloss_val = np.median(np.array(metrics['logloss']))\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º child run –¥–ª—è —ç—Ç–æ–≥–æ trial\n",
    "    with mlflow.start_run(experiment_id=experiment_id, nested=True) as child_run:\n",
    "        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–≥ —Å parent run id\n",
    "        mlflow.set_tag(\"mlflow.parentRunId\", parent_run_id)\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "        mlflow.log_params(param)\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        mlflow.log_metrics({\n",
    "            \"err1\": err_1,\n",
    "            \"err2\": err_2,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"logloss\": logloss_val\n",
    "        })\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimization_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ/–ø–æ–ª—É—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –±–∞–π–µ—Å–æ–≤—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º experiment_id\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ study\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=STUDY_DB_NAME,\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ - —Å–æ–∑–¥–∞–µ–º parent run\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as parent_run:\n",
    "    parent_run_id = parent_run.info.run_id\n",
    "    print(f\"\\nParent MLflow Run ID: {parent_run_id}\")\n",
    "    \n",
    "    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å 10 —Ç—Ä–∏–∞–ª–∞–º–∏\n",
    "    print(f\"\\nüîç –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å 10 trials...\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    best_params = study.best_params\n",
    "    best_auc = study.best_value\n",
    "    \n",
    "    print(f\"\\n‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    print(f\"–õ—É—á—à–∏–π AUC: {best_auc:.4f}\")\n",
    "    print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params}\")\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö train –¥–∞–Ω–Ω—ã—Ö\n",
    "    final_params = {\n",
    "        **best_params,\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"task_type\": \"CPU\", \n",
    "        \"random_seed\": 0,\n",
    "        \"iterations\": 300,\n",
    "        \"verbose\": False\n",
    "    }\n",
    "    \n",
    "    best_model = CatBoostClassifier(**final_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ parent run —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–º 'cv'\n",
    "    mlflow.catboost.log_model(best_model, \"cv\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –Ω–∞ test –¥–∞–Ω–Ω—ã—Ö\n",
    "    test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "    cm_test = confusion_matrix(y_test, test_pred, normalize='all')\n",
    "    tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
    "    \n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "    test_precision = precision_score(y_test, test_pred)\n",
    "    test_recall = recall_score(y_test, test_pred)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    test_logloss = log_loss(y_test, test_proba)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –≤ parent run\n",
    "    mlflow.log_metric(\"test_auc\", test_auc)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_logloss\", test_logloss)\n",
    "    mlflow.log_metric(\"test_err1\", fp_test)\n",
    "    mlflow.log_metric(\"test_err2\", fn_test)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ CV –º–µ—Ç—Ä–∏–∫\n",
    "    mlflow.log_metric(\"cv_best_auc\", best_auc)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_param(\"iterations\", 300)\n",
    "    mlflow.log_param(\"loss_function\", \"Logloss\")\n",
    "    mlflow.log_param(\"task_type\", \"CPU\")\n",
    "    mlflow.log_param(\"random_seed\", 0)\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"cv_folds\", 2)\n",
    "    mlflow.log_param(\"search_method\", \"TPESampler\")\n",
    "    mlflow.log_param(\"n_trials\", 10)\n",
    "    \n",
    "    print(\"\\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow!\")\n",
    "    print(f\"Parent Run ID: {parent_run.info.run_id}\")\n",
    "    print(f\"\\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:\")\n",
    "    print(f\"   ROC-AUC: {test_auc:.4f}\")\n",
    "    print(f\"   Precision: {test_precision:.4f}\")\n",
    "    print(f\"   Recall: {test_recall:.4f}\")\n",
    "    print(f\"   F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç—Ä–∏–∞–ª–æ–≤: {len(study.trials)}\")\n",
    "print(f\"–õ—É—á—à–∏–π CV AUC: {study.best_value:.4f}\")\n",
    "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}\")\n",
    "print(f\"\\nParent Run ID: {parent_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verification_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ child runs\n",
    "filter_string = f\"tags.mlflow.parentRunId = '{parent_run_id}'\"\n",
    "child_runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=filter_string\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"–ü–†–û–í–ï–†–ö–ê CHILD RUNS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Parent Run ID: {parent_run_id}\")\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ child runs: {len(child_runs)}\")\n",
    "\n",
    "if len(child_runs) == 10:\n",
    "    print(\"‚úÖ –ù–∞–π–¥–µ–Ω–æ 10 child runs\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è –û–∂–∏–¥–∞–ª–æ—Å—å 10 child runs, –Ω–∞–π–¥–µ–Ω–æ {len(child_runs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ml_project (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
